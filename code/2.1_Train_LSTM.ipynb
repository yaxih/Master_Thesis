{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "759077a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, SimpleRNN, Input, BatchNormalization\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1e0a8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from collections import Counter\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "from datetime import datetime,timedelta\n",
    "from math import log, sqrt\n",
    "import pandas as pd\n",
    "import distance\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from jellyfish._jellyfish import damerau_levenshtein_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df68fe",
   "metadata": {},
   "source": [
    "# 1.Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "27ddbfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventlog = \"preprocessed_bpi13_lowV.csv\"\n",
    "eventlog_name = \"bpi13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4b969382",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open('../data/%s' % eventlog, 'r')\n",
    "spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "next(spamreader, None)  # skip the headers\n",
    "ascii_offset = 161"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab23378",
   "metadata": {},
   "source": [
    "# 2.Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "027e6f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [] #these are all the activity seq\n",
    "timeseqs = [] #time sequences (differences between two events)\n",
    "timeseqs2 = [] #time sequences (differences between the current and first)\n",
    "\n",
    "#helper variables\n",
    "lastcase = ''\n",
    "line = ''\n",
    "firstLine = True\n",
    "times = []\n",
    "times2 = []\n",
    "numlines = 0\n",
    "casestarttime = None\n",
    "lasteventtime = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "32e1e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in spamreader: #the rows are \"CaseID,ActivityID,CompleteTimestamp\"\n",
    "    t = datetime.strptime(row[2], \"%Y-%m-%d %H:%M:%S\") #creates a datetime object from row[2]\n",
    "    if row[0]!=lastcase:  #'lastcase' is to save the last executed case for the loop\n",
    "        casestarttime = t\n",
    "        lasteventtime = t\n",
    "        lastcase = row[0]\n",
    "        if not firstLine:\n",
    "            lines.append(line)\n",
    "            timeseqs.append(times)\n",
    "            timeseqs2.append(times2)\n",
    "        line = ''\n",
    "        times = []\n",
    "        times2 = []\n",
    "        numlines+=1\n",
    "    line+=chr(int(row[1])+ascii_offset)\n",
    "    timesincelastevent = t - lasteventtime\n",
    "    timesincecasestart = t - casestarttime\n",
    "    timediff = 86400 * timesincelastevent.days + timesincelastevent.seconds  #time b/t current and last event\n",
    "    timediff2 = 86400 * timesincecasestart.days + timesincecasestart.seconds #time b/t current and starting event\n",
    "    times.append(timediff)\n",
    "    times2.append(timediff2)\n",
    "    lasteventtime = t\n",
    "    firstLine = False\n",
    "\n",
    "# add last case\n",
    "lines.append(line)\n",
    "timeseqs.append(times)\n",
    "timeseqs2.append(times2)\n",
    "numlines+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "91178c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of accessing processed data\n",
    "#print(lines)\n",
    "#print(timeseqs)\n",
    "#print(timeseqs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e7048d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divisor: 115683.72903116817\n",
      "divisor2: 521824.4638905313\n"
     ]
    }
   ],
   "source": [
    "#average time between events\n",
    "divisor = np.mean([item for sublist in timeseqs for item in sublist]) \n",
    "print('divisor: {}'.format(divisor))\n",
    "#average time between current and starting events\n",
    "divisor2 = np.mean([item for sublist in timeseqs2 for item in sublist]) \n",
    "print('divisor2: {}'.format(divisor2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "57247802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate training data into 3 parts\n",
    "elems_per_fold = int(round(numlines/3)) #calculate the number of elements per fold\n",
    "# fist 1/3 elements and their calculated time features\n",
    "fold1 = lines[:elems_per_fold]\n",
    "fold1_t = timeseqs[:elems_per_fold]\n",
    "fold1_t2 = timeseqs2[:elems_per_fold]\n",
    "# second 1/3 elements and their calculated time features\n",
    "fold2 = lines[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t = timeseqs[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t2 = timeseqs2[elems_per_fold:2*elems_per_fold]\n",
    "# last 1/3 elements and their calculated time features\n",
    "fold3 = lines[2*elems_per_fold:]\n",
    "fold3_t = timeseqs[2*elems_per_fold:]\n",
    "fold3_t2 = timeseqs2[2*elems_per_fold:]\n",
    "\n",
    "#consider only fist and second part as training set, leave away fold3 for now\n",
    "lines = fold1 + fold2\n",
    "lines_t = fold1_t + fold2_t\n",
    "lines_t2 = fold1_t2 + fold2_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "83fbe20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "sentences = []\n",
    "softness = 0\n",
    "next_chars = []\n",
    "lines = list(map(lambda x: x+ '!',lines)) #add a delimiter symbol '!' to the end of each line\n",
    "maxlen = max(map(lambda x: len(x),lines)) #find maximum line size\n",
    "\n",
    "# next lines here to get all possible characters for events and annotate them with numbers\n",
    "chars = list(map(lambda x: set(x),lines))\n",
    "chars = list(set().union(*chars))\n",
    "chars.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ea278822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 10, target chars: 11\n"
     ]
    }
   ],
   "source": [
    "target_chars = copy.copy(chars)\n",
    "\n",
    "if '!' in chars:\n",
    "    chars.remove('!')\n",
    "print('total chars: {}, target chars: {}'.format(len(chars), len(target_chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "859f59f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '¢', 1: '£', 2: '¤', 3: '¥', 4: '¦', 5: '§', 6: '¨', 7: '©', 8: 'ª', 9: '«'}\n"
     ]
    }
   ],
   "source": [
    "#get the target chars from the training set\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "target_char_indices = dict((c, i) for i, c in enumerate(target_chars))\n",
    "target_indices_char = dict((i, c) for i, c in enumerate(target_chars))\n",
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5cb884",
   "metadata": {},
   "source": [
    "# 3. Feature Enginnering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "59bc4801",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open('../data/%s' % eventlog, 'r')\n",
    "spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "next(spamreader, None)  # skip the headers\n",
    "lastcase = ''\n",
    "line = ''\n",
    "firstLine = True\n",
    "lines = []\n",
    "timeseqs = []\n",
    "timeseqs2 = []\n",
    "timeseqs3 = []\n",
    "timeseqs4 = []\n",
    "times = []\n",
    "times2 = []\n",
    "times3 = []\n",
    "times4 = []\n",
    "numlines = 0\n",
    "casestarttime = None\n",
    "lasteventtime = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a5147c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in spamreader:\n",
    "    t = time.strptime(row[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "    if row[0]!=lastcase:\n",
    "        casestarttime = t\n",
    "        lasteventtime = t\n",
    "        lastcase = row[0]\n",
    "        if not firstLine:\n",
    "            lines.append(line)\n",
    "            timeseqs.append(times)\n",
    "            timeseqs2.append(times2)\n",
    "            timeseqs3.append(times3)\n",
    "            timeseqs4.append(times4)\n",
    "        line = ''\n",
    "        times = []\n",
    "        times2 = []\n",
    "        times3 = []\n",
    "        times4 = []\n",
    "        numlines+=1\n",
    "    line+=chr(int(row[1])+ascii_offset)\n",
    "    timesincelastevent = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(lasteventtime))\n",
    "    timesincecasestart = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(casestarttime))\n",
    "    midnight = datetime.fromtimestamp(time.mktime(t)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    timesincemidnight = datetime.fromtimestamp(time.mktime(t))-midnight\n",
    "    timediff = 86400 * timesincelastevent.days + timesincelastevent.seconds\n",
    "    timediff2 = 86400 * timesincecasestart.days + timesincecasestart.seconds\n",
    "    timediff3 = timesincemidnight.seconds #this leaves only time even occurred after midnight\n",
    "    timediff4 = datetime.fromtimestamp(time.mktime(t)).weekday() #day of the week\n",
    "    times.append(timediff)\n",
    "    times2.append(timediff2)\n",
    "    times3.append(timediff3)\n",
    "    times4.append(timediff4)\n",
    "    lasteventtime = t\n",
    "    firstLine = False\n",
    "\n",
    "# add last case\n",
    "lines.append(line)\n",
    "timeseqs.append(times)\n",
    "timeseqs2.append(times2)\n",
    "timeseqs3.append(times3)\n",
    "timeseqs4.append(times4)\n",
    "numlines+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7714ebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold 1\n",
    "elems_per_fold = int(round(numlines/3)) #calculate the number of elements per fold\n",
    "fold1 = lines[:elems_per_fold]\n",
    "fold1_t = timeseqs[:elems_per_fold]\n",
    "fold1_t2 = timeseqs2[:elems_per_fold]\n",
    "fold1_t3 = timeseqs3[:elems_per_fold]\n",
    "fold1_t4 = timeseqs4[:elems_per_fold]\n",
    "with open(f'output_files/folds/{eventlog_name}_fold1.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row, timeseq in zip(fold1, fold1_t):\n",
    "        spamwriter.writerow([str(s) + '#{}'.format(t) for s, t in zip(row, timeseq)])\n",
    "        \n",
    "# fold 2\n",
    "fold2 = lines[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t = timeseqs[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t2 = timeseqs2[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t3 = timeseqs3[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t4 = timeseqs4[elems_per_fold:2*elems_per_fold]\n",
    "with open(f'output_files/folds/{eventlog_name}_fold2.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row, timeseq in zip(fold2, fold2_t):\n",
    "        spamwriter.writerow([str(s) +'#{}'.format(t) for s, t in zip(row, timeseq)])\n",
    "        \n",
    "# fold 3\n",
    "fold3 = lines[2*elems_per_fold:]\n",
    "fold3_t = timeseqs[2*elems_per_fold:]\n",
    "fold3_t2 = timeseqs2[2*elems_per_fold:]\n",
    "fold3_t3 = timeseqs3[2*elems_per_fold:]\n",
    "fold3_t4 = timeseqs4[2*elems_per_fold:]\n",
    "with open(f'output_files/folds/{eventlog_name}_fold3.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row, timeseq in zip(fold3, fold3_t):\n",
    "        spamwriter.writerow([str(s) +'#{}'.format(t) for s, t in zip(row, timeseq)])\n",
    "        \n",
    "lines = fold1 + fold2\n",
    "lines_t = fold1_t + fold2_t\n",
    "lines_t2 = fold1_t2 + fold2_t2\n",
    "lines_t3 = fold1_t3 + fold2_t3\n",
    "lines_t4 = fold1_t4 + fold2_t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "2e359f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 22263\n"
     ]
    }
   ],
   "source": [
    "step = 1\n",
    "sentences = []\n",
    "softness = 0\n",
    "next_chars = []\n",
    "lines = list(map(lambda x: x+'!', lines))\n",
    "\n",
    "sentences_t = []\n",
    "sentences_t2 = []\n",
    "sentences_t3 = []\n",
    "sentences_t4 = []\n",
    "next_chars_t = []\n",
    "next_chars_t2 = []\n",
    "next_chars_t3 = []\n",
    "next_chars_t4 = []\n",
    "\n",
    "for line, line_t, line_t2, line_t3, line_t4 in zip(lines, lines_t, lines_t2, lines_t3, lines_t4):\n",
    "    for i in range(0, len(line), step):\n",
    "        if i==0:\n",
    "            continue\n",
    "\n",
    "        #we add iteratively, first symbol of the line, then two first, three...\n",
    "        sentences.append(line[0: i])\n",
    "        sentences_t.append(line_t[0:i])\n",
    "        sentences_t2.append(line_t2[0:i])\n",
    "        sentences_t3.append(line_t3[0:i])\n",
    "        sentences_t4.append(line_t4[0:i])\n",
    "        next_chars.append(line[i])\n",
    "\n",
    "        if i==len(line)-1: # special case to deal time of end character\n",
    "            next_chars_t.append(0)\n",
    "            next_chars_t2.append(0)\n",
    "            next_chars_t3.append(0)\n",
    "            next_chars_t4.append(0)\n",
    "        else:\n",
    "            next_chars_t.append(line_t[i])\n",
    "            next_chars_t2.append(line_t2[i])\n",
    "            next_chars_t3.append(line_t3[i])\n",
    "            next_chars_t4.append(line_t4[i])\n",
    "\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d239d0a3",
   "metadata": {},
   "source": [
    "# 4. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "928f529a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "num features: 15\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "num_features = len(chars)+5\n",
    "print('num features: {}'.format(num_features))\n",
    "X = np.zeros((len(sentences), maxlen, num_features), dtype=np.float32)\n",
    "y_a = np.zeros((len(sentences), len(target_chars)), dtype=np.float32)\n",
    "y_t = np.zeros((len(sentences)), dtype=np.float32)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    leftpad = maxlen-len(sentence)\n",
    "    next_t = next_chars_t[i]\n",
    "    sentence_t = sentences_t[i]\n",
    "    sentence_t2 = sentences_t2[i]\n",
    "    sentence_t3 = sentences_t3[i]\n",
    "    sentence_t4 = sentences_t4[i]\n",
    "    for t, char in enumerate(sentence):\n",
    "        multiset_abstraction = Counter(sentence[:t+1])\n",
    "        for c in chars:\n",
    "            if c==char: #this will encode present events to the right places\n",
    "                X[i, t+leftpad, char_indices[c]] = 1\n",
    "        X[i, t+leftpad, len(chars)] = t+1\n",
    "        X[i, t+leftpad, len(chars)+1] = sentence_t[t]/divisor\n",
    "        X[i, t+leftpad, len(chars)+2] = sentence_t2[t]/divisor2\n",
    "        X[i, t+leftpad, len(chars)+3] = sentence_t3[t]/86400\n",
    "        X[i, t+leftpad, len(chars)+4] = sentence_t4[t]/7\n",
    "    for c in target_chars:\n",
    "        if c==next_chars[i]:\n",
    "            y_a[i, target_char_indices[c]] = 1-softness\n",
    "        else:\n",
    "            y_a[i, target_char_indices[c]] = softness/(len(target_chars)-1)\n",
    "    y_t[i] = next_t/divisor\n",
    "    np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfa6699",
   "metadata": {},
   "source": [
    "# 5. Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "19430748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1815163d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "main_input = Input(shape=(maxlen, num_features), name='main_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "21074ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a 2-layer LSTM with one shared layer\n",
    "l1 = LSTM(100, implementation=2, kernel_initializer='glorot_uniform', return_sequences=True, dropout=0.2)(main_input) # the shared layer\n",
    "b1 = BatchNormalization()(l1)\n",
    "l2_1 = LSTM(100, implementation=2, kernel_initializer='glorot_uniform', return_sequences=False, dropout=0.2)(b1) # the layer specialized in activity prediction\n",
    "b2_1 = BatchNormalization()(l2_1)\n",
    "l2_2 = LSTM(100, implementation=2, kernel_initializer='glorot_uniform', return_sequences=False, dropout=0.2)(b1) # the layer specialized in time prediction\n",
    "b2_2 = BatchNormalization()(l2_2)\n",
    "act_output = Dense(len(target_chars), activation='softmax', kernel_initializer='glorot_uniform', name='act_output')(b2_1)\n",
    "time_output = Dense(1, kernel_initializer='glorot_uniform', name='time_output')(b2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "2854386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[main_input], outputs=[act_output, time_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "9b14183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = legacy.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.004, clipvalue=3)\n",
    "model.compile(loss={'act_output':'categorical_crossentropy', 'time_output':'mae'}, optimizer=opt)\n",
    "early_stopping = EarlyStopping(monitor='val_act_output_loss', patience=42)\n",
    "model_checkpoint = ModelCheckpoint('output_files/models/LSTM_model_{epoch:02d}-{val_act_output_loss:.2f}.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_act_output_loss', factor=0.5, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f30c5975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1370/1370 - 45s - loss: 1.5789 - act_output_loss: 0.6946 - time_output_loss: 0.8843 - val_loss: 2.1651 - val_act_output_loss: 1.2603 - val_time_output_loss: 0.9049 - lr: 0.0020 - 45s/epoch - 33ms/step\n",
      "Epoch 2/500\n",
      "1370/1370 - 37s - loss: 1.3383 - act_output_loss: 0.5451 - time_output_loss: 0.7932 - val_loss: 2.0873 - val_act_output_loss: 1.1970 - val_time_output_loss: 0.8903 - lr: 0.0020 - 37s/epoch - 27ms/step\n",
      "Epoch 3/500\n",
      "1370/1370 - 40s - loss: 1.3239 - act_output_loss: 0.5294 - time_output_loss: 0.7945 - val_loss: 2.2731 - val_act_output_loss: 1.3433 - val_time_output_loss: 0.9297 - lr: 0.0020 - 40s/epoch - 29ms/step\n",
      "Epoch 4/500\n",
      "1370/1370 - 38s - loss: 1.2987 - act_output_loss: 0.5212 - time_output_loss: 0.7775 - val_loss: 2.2928 - val_act_output_loss: 1.3910 - val_time_output_loss: 0.9019 - lr: 0.0020 - 38s/epoch - 28ms/step\n",
      "Epoch 5/500\n",
      "1370/1370 - 39s - loss: 1.2901 - act_output_loss: 0.5193 - time_output_loss: 0.7708 - val_loss: 2.2558 - val_act_output_loss: 1.4229 - val_time_output_loss: 0.8329 - lr: 0.0020 - 39s/epoch - 28ms/step\n",
      "Epoch 6/500\n",
      "1370/1370 - 38s - loss: 1.2913 - act_output_loss: 0.5181 - time_output_loss: 0.7732 - val_loss: 2.3295 - val_act_output_loss: 1.4459 - val_time_output_loss: 0.8837 - lr: 0.0020 - 38s/epoch - 28ms/step\n",
      "Epoch 7/500\n",
      "1370/1370 - 39s - loss: 1.2592 - act_output_loss: 0.5022 - time_output_loss: 0.7570 - val_loss: 2.3626 - val_act_output_loss: 1.4720 - val_time_output_loss: 0.8905 - lr: 0.0020 - 39s/epoch - 29ms/step\n",
      "Epoch 8/500\n",
      "1370/1370 - 41s - loss: 1.2555 - act_output_loss: 0.5032 - time_output_loss: 0.7522 - val_loss: 2.4300 - val_act_output_loss: 1.5047 - val_time_output_loss: 0.9253 - lr: 0.0020 - 41s/epoch - 30ms/step\n",
      "Epoch 9/500\n",
      "1370/1370 - 38s - loss: 1.2414 - act_output_loss: 0.5020 - time_output_loss: 0.7394 - val_loss: 2.3315 - val_act_output_loss: 1.4754 - val_time_output_loss: 0.8561 - lr: 0.0020 - 38s/epoch - 28ms/step\n",
      "Epoch 10/500\n",
      "1370/1370 - 38s - loss: 1.2601 - act_output_loss: 0.5039 - time_output_loss: 0.7563 - val_loss: 2.3001 - val_act_output_loss: 1.4400 - val_time_output_loss: 0.8601 - lr: 0.0020 - 38s/epoch - 28ms/step\n",
      "Epoch 11/500\n",
      "1370/1370 - 42s - loss: 1.2529 - act_output_loss: 0.5034 - time_output_loss: 0.7495 - val_loss: 2.4886 - val_act_output_loss: 1.5431 - val_time_output_loss: 0.9455 - lr: 0.0020 - 42s/epoch - 31ms/step\n",
      "Epoch 12/500\n",
      "1370/1370 - 41s - loss: 1.2436 - act_output_loss: 0.5024 - time_output_loss: 0.7412 - val_loss: 2.3705 - val_act_output_loss: 1.5059 - val_time_output_loss: 0.8646 - lr: 0.0020 - 41s/epoch - 30ms/step\n",
      "Epoch 13/500\n",
      "1370/1370 - 42s - loss: 1.2157 - act_output_loss: 0.4885 - time_output_loss: 0.7271 - val_loss: 2.4470 - val_act_output_loss: 1.5447 - val_time_output_loss: 0.9023 - lr: 0.0010 - 42s/epoch - 31ms/step\n",
      "Epoch 14/500\n",
      "1370/1370 - 58s - loss: 1.2164 - act_output_loss: 0.4876 - time_output_loss: 0.7288 - val_loss: 2.5001 - val_act_output_loss: 1.6276 - val_time_output_loss: 0.8725 - lr: 0.0010 - 58s/epoch - 42ms/step\n",
      "Epoch 15/500\n",
      "1370/1370 - 39s - loss: 1.2136 - act_output_loss: 0.4858 - time_output_loss: 0.7278 - val_loss: 2.4978 - val_act_output_loss: 1.6182 - val_time_output_loss: 0.8796 - lr: 0.0010 - 39s/epoch - 28ms/step\n",
      "Epoch 16/500\n",
      "1370/1370 - 45s - loss: 1.2144 - act_output_loss: 0.4871 - time_output_loss: 0.7273 - val_loss: 2.5493 - val_act_output_loss: 1.6592 - val_time_output_loss: 0.8900 - lr: 0.0010 - 45s/epoch - 33ms/step\n",
      "Epoch 17/500\n",
      "1370/1370 - 40s - loss: 1.1963 - act_output_loss: 0.4835 - time_output_loss: 0.7127 - val_loss: 2.6284 - val_act_output_loss: 1.7142 - val_time_output_loss: 0.9142 - lr: 0.0010 - 40s/epoch - 29ms/step\n",
      "Epoch 18/500\n",
      "1370/1370 - 39s - loss: 1.2181 - act_output_loss: 0.4914 - time_output_loss: 0.7267 - val_loss: 2.5779 - val_act_output_loss: 1.6790 - val_time_output_loss: 0.8989 - lr: 0.0010 - 39s/epoch - 29ms/step\n",
      "Epoch 19/500\n",
      "1370/1370 - 41s - loss: 1.2067 - act_output_loss: 0.4842 - time_output_loss: 0.7225 - val_loss: 2.6047 - val_act_output_loss: 1.7078 - val_time_output_loss: 0.8969 - lr: 0.0010 - 41s/epoch - 30ms/step\n",
      "Epoch 20/500\n",
      "1370/1370 - 44s - loss: 1.2084 - act_output_loss: 0.4865 - time_output_loss: 0.7220 - val_loss: 2.5985 - val_act_output_loss: 1.7102 - val_time_output_loss: 0.8883 - lr: 0.0010 - 44s/epoch - 32ms/step\n",
      "Epoch 21/500\n",
      "1370/1370 - 46s - loss: 1.2083 - act_output_loss: 0.4818 - time_output_loss: 0.7265 - val_loss: 2.6585 - val_act_output_loss: 1.7429 - val_time_output_loss: 0.9157 - lr: 0.0010 - 46s/epoch - 33ms/step\n",
      "Epoch 22/500\n",
      "1370/1370 - 52s - loss: 1.2163 - act_output_loss: 0.4832 - time_output_loss: 0.7331 - val_loss: 2.6780 - val_act_output_loss: 1.7688 - val_time_output_loss: 0.9092 - lr: 0.0010 - 52s/epoch - 38ms/step\n",
      "Epoch 23/500\n",
      "1370/1370 - 73s - loss: 1.1962 - act_output_loss: 0.4778 - time_output_loss: 0.7184 - val_loss: 2.6980 - val_act_output_loss: 1.7532 - val_time_output_loss: 0.9449 - lr: 5.0000e-04 - 73s/epoch - 53ms/step\n",
      "Epoch 24/500\n",
      "1370/1370 - 89s - loss: 1.1948 - act_output_loss: 0.4762 - time_output_loss: 0.7186 - val_loss: 2.6240 - val_act_output_loss: 1.7230 - val_time_output_loss: 0.9010 - lr: 5.0000e-04 - 89s/epoch - 65ms/step\n",
      "Epoch 25/500\n",
      "1370/1370 - 71s - loss: 1.1839 - act_output_loss: 0.4758 - time_output_loss: 0.7081 - val_loss: 2.6321 - val_act_output_loss: 1.7244 - val_time_output_loss: 0.9077 - lr: 5.0000e-04 - 71s/epoch - 52ms/step\n",
      "Epoch 26/500\n",
      "1370/1370 - 54s - loss: 1.1901 - act_output_loss: 0.4733 - time_output_loss: 0.7168 - val_loss: 2.6311 - val_act_output_loss: 1.7212 - val_time_output_loss: 0.9099 - lr: 5.0000e-04 - 54s/epoch - 40ms/step\n",
      "Epoch 27/500\n",
      "1370/1370 - 40s - loss: 1.1840 - act_output_loss: 0.4784 - time_output_loss: 0.7056 - val_loss: 2.6574 - val_act_output_loss: 1.7533 - val_time_output_loss: 0.9041 - lr: 5.0000e-04 - 40s/epoch - 29ms/step\n",
      "Epoch 28/500\n",
      "1370/1370 - 42s - loss: 1.1920 - act_output_loss: 0.4786 - time_output_loss: 0.7134 - val_loss: 2.6647 - val_act_output_loss: 1.7451 - val_time_output_loss: 0.9196 - lr: 5.0000e-04 - 42s/epoch - 31ms/step\n",
      "Epoch 29/500\n",
      "1370/1370 - 49s - loss: 1.2030 - act_output_loss: 0.4746 - time_output_loss: 0.7285 - val_loss: 2.6739 - val_act_output_loss: 1.7670 - val_time_output_loss: 0.9069 - lr: 5.0000e-04 - 49s/epoch - 36ms/step\n",
      "Epoch 30/500\n",
      "1370/1370 - 47s - loss: 1.1809 - act_output_loss: 0.4713 - time_output_loss: 0.7096 - val_loss: 2.6246 - val_act_output_loss: 1.7743 - val_time_output_loss: 0.8503 - lr: 5.0000e-04 - 47s/epoch - 35ms/step\n",
      "Epoch 31/500\n",
      "1370/1370 - 47s - loss: 1.1938 - act_output_loss: 0.4741 - time_output_loss: 0.7197 - val_loss: 2.7454 - val_act_output_loss: 1.8137 - val_time_output_loss: 0.9317 - lr: 5.0000e-04 - 47s/epoch - 34ms/step\n",
      "Epoch 32/500\n",
      "1370/1370 - 44s - loss: 1.1859 - act_output_loss: 0.4723 - time_output_loss: 0.7136 - val_loss: 2.7235 - val_act_output_loss: 1.8270 - val_time_output_loss: 0.8965 - lr: 5.0000e-04 - 44s/epoch - 32ms/step\n",
      "Epoch 33/500\n",
      "1370/1370 - 47s - loss: 1.1810 - act_output_loss: 0.4712 - time_output_loss: 0.7098 - val_loss: 2.7023 - val_act_output_loss: 1.7957 - val_time_output_loss: 0.9067 - lr: 2.5000e-04 - 47s/epoch - 34ms/step\n",
      "Epoch 34/500\n",
      "1370/1370 - 43s - loss: 1.1826 - act_output_loss: 0.4707 - time_output_loss: 0.7119 - val_loss: 2.7111 - val_act_output_loss: 1.8176 - val_time_output_loss: 0.8935 - lr: 2.5000e-04 - 43s/epoch - 31ms/step\n",
      "Epoch 35/500\n",
      "1370/1370 - 46s - loss: 1.1756 - act_output_loss: 0.4690 - time_output_loss: 0.7066 - val_loss: 2.7600 - val_act_output_loss: 1.8345 - val_time_output_loss: 0.9255 - lr: 2.5000e-04 - 46s/epoch - 34ms/step\n",
      "Epoch 36/500\n",
      "1370/1370 - 45s - loss: 1.1884 - act_output_loss: 0.4767 - time_output_loss: 0.7117 - val_loss: 2.7603 - val_act_output_loss: 1.8247 - val_time_output_loss: 0.9356 - lr: 2.5000e-04 - 45s/epoch - 33ms/step\n",
      "Epoch 37/500\n",
      "1370/1370 - 50s - loss: 1.1843 - act_output_loss: 0.4682 - time_output_loss: 0.7161 - val_loss: 2.7759 - val_act_output_loss: 1.8341 - val_time_output_loss: 0.9418 - lr: 2.5000e-04 - 50s/epoch - 37ms/step\n",
      "Epoch 38/500\n",
      "1370/1370 - 44s - loss: 1.1678 - act_output_loss: 0.4661 - time_output_loss: 0.7017 - val_loss: 2.7721 - val_act_output_loss: 1.8522 - val_time_output_loss: 0.9199 - lr: 2.5000e-04 - 44s/epoch - 32ms/step\n",
      "Epoch 39/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1370/1370 - 41s - loss: 1.1755 - act_output_loss: 0.4692 - time_output_loss: 0.7063 - val_loss: 2.7810 - val_act_output_loss: 1.8537 - val_time_output_loss: 0.9273 - lr: 2.5000e-04 - 41s/epoch - 30ms/step\n",
      "Epoch 40/500\n",
      "1370/1370 - 41s - loss: 1.1797 - act_output_loss: 0.4740 - time_output_loss: 0.7057 - val_loss: 2.7972 - val_act_output_loss: 1.8611 - val_time_output_loss: 0.9361 - lr: 2.5000e-04 - 41s/epoch - 30ms/step\n",
      "Epoch 41/500\n",
      "1370/1370 - 40s - loss: 1.1687 - act_output_loss: 0.4681 - time_output_loss: 0.7005 - val_loss: 2.7208 - val_act_output_loss: 1.8074 - val_time_output_loss: 0.9133 - lr: 2.5000e-04 - 40s/epoch - 29ms/step\n",
      "Epoch 42/500\n",
      "1370/1370 - 41s - loss: 1.1700 - act_output_loss: 0.4724 - time_output_loss: 0.6976 - val_loss: 2.7417 - val_act_output_loss: 1.8302 - val_time_output_loss: 0.9114 - lr: 2.5000e-04 - 41s/epoch - 30ms/step\n",
      "Epoch 43/500\n",
      "1370/1370 - 38s - loss: 1.1732 - act_output_loss: 0.4689 - time_output_loss: 0.7043 - val_loss: 2.7291 - val_act_output_loss: 1.8233 - val_time_output_loss: 0.9058 - lr: 1.2500e-04 - 38s/epoch - 28ms/step\n",
      "Epoch 44/500\n",
      "1370/1370 - 39s - loss: 1.1856 - act_output_loss: 0.4692 - time_output_loss: 0.7164 - val_loss: 2.7064 - val_act_output_loss: 1.8051 - val_time_output_loss: 0.9014 - lr: 1.2500e-04 - 39s/epoch - 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b856032b0>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, {'act_output':y_a, 'time_output':y_t}, validation_split=0.2, verbose=2, callbacks=[early_stopping, model_checkpoint, lr_reducer], batch_size=maxlen, epochs=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
