{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e0a8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from collections import Counter\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "from datetime import datetime,timedelta\n",
    "from math import log, sqrt\n",
    "import pandas as pd\n",
    "import distance\n",
    "import matplotlib.pyplot as plt\n",
    "from jellyfish._jellyfish import damerau_levenshtein_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df68fe",
   "metadata": {},
   "source": [
    "# 1.Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27ddbfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventlog = \"env_permit.csv\"\n",
    "eventlog_name = \"env_permit\"\n",
    "ori_eventlog=\"env_permit.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42eeca7-7df1-4581-bb45-bedbcfc242ab",
   "metadata": {},
   "source": [
    "# 1.1. Calculate Maxlen and Target labels\n",
    "\n",
    "to make sure the model is compile with different sized test set, the shape of the training set needs to be the same.\n",
    "Thus, maxlen is loaded as the maximum length of a trace from the original log, target_chars is loaded as all possible characters from the original log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79d92b3b-5119-4676-8631-acf0a689e6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset env_permit.csv\n",
      "maxlen: 96\n",
      "total chars: 381, target chars: 382\n",
      "{0: '¢', 1: '£', 2: '¤', 3: '¥', 4: '¦', 5: '§', 6: '¨', 7: '©', 8: 'ª', 9: '«', 10: '¬', 11: '\\xad', 12: '®', 13: '¯', 14: '°', 15: '±', 16: '²', 17: '³', 18: '´', 19: 'µ', 20: '¶', 21: '·', 22: '¸', 23: '¹', 24: 'º', 25: '»', 26: '¼', 27: '½', 28: '¾', 29: '¿', 30: 'À', 31: 'Á', 32: 'Â', 33: 'Ã', 34: 'Ä', 35: 'Å', 36: 'Æ', 37: 'Ç', 38: 'È', 39: 'É', 40: 'Ê', 41: 'Ë', 42: 'Ì', 43: 'Í', 44: 'Î', 45: 'Ï', 46: 'Ð', 47: 'Ñ', 48: 'Ò', 49: 'Ó', 50: 'Ô', 51: 'Õ', 52: 'Ö', 53: '×', 54: 'Ø', 55: 'Ù', 56: 'Ú', 57: 'Û', 58: 'Ü', 59: 'Ý', 60: 'Þ', 61: 'ß', 62: 'à', 63: 'á', 64: 'â', 65: 'ã', 66: 'ä', 67: 'å', 68: 'æ', 69: 'ç', 70: 'è', 71: 'é', 72: 'ê', 73: 'ë', 74: 'ì', 75: 'í', 76: 'î', 77: 'ï', 78: 'ð', 79: 'ñ', 80: 'ò', 81: 'ó', 82: 'ô', 83: 'õ', 84: 'ö', 85: '÷', 86: 'ø', 87: 'ù', 88: 'ú', 89: 'û', 90: 'ü', 91: 'ý', 92: 'þ', 93: 'ÿ', 94: 'Ā', 95: 'ā', 96: 'Ă', 97: 'ă', 98: 'Ą', 99: 'ą', 100: 'Ć', 101: 'ć', 102: 'Ĉ', 103: 'ĉ', 104: 'Ċ', 105: 'ċ', 106: 'Č', 107: 'č', 108: 'Ď', 109: 'ď', 110: 'Đ', 111: 'đ', 112: 'Ē', 113: 'ē', 114: 'Ĕ', 115: 'ĕ', 116: 'Ė', 117: 'ė', 118: 'Ę', 119: 'ę', 120: 'Ě', 121: 'ě', 122: 'Ĝ', 123: 'ĝ', 124: 'Ğ', 125: 'ğ', 126: 'Ġ', 127: 'ġ', 128: 'Ģ', 129: 'ģ', 130: 'Ĥ', 131: 'ĥ', 132: 'Ħ', 133: 'ħ', 134: 'Ĩ', 135: 'ĩ', 136: 'Ī', 137: 'ī', 138: 'Ĭ', 139: 'ĭ', 140: 'Į', 141: 'į', 142: 'İ', 143: 'ı', 144: 'Ĳ', 145: 'ĳ', 146: 'Ĵ', 147: 'ĵ', 148: 'Ķ', 149: 'ķ', 150: 'ĸ', 151: 'Ĺ', 152: 'ĺ', 153: 'Ļ', 154: 'ļ', 155: 'Ľ', 156: 'ľ', 157: 'Ŀ', 158: 'ŀ', 159: 'Ł', 160: 'ł', 161: 'Ń', 162: 'ń', 163: 'Ņ', 164: 'ņ', 165: 'Ň', 166: 'ň', 167: 'ŉ', 168: 'Ŋ', 169: 'ŋ', 170: 'Ō', 171: 'ō', 172: 'Ŏ', 173: 'ŏ', 174: 'Ő', 175: 'ő', 176: 'Œ', 177: 'œ', 178: 'Ŕ', 179: 'ŕ', 180: 'Ŗ', 181: 'ŗ', 182: 'Ř', 183: 'ř', 184: 'Ś', 185: 'ś', 186: 'Ŝ', 187: 'ŝ', 188: 'Ş', 189: 'ş', 190: 'Š', 191: 'š', 192: 'Ţ', 193: 'ţ', 194: 'Ť', 195: 'ť', 196: 'Ŧ', 197: 'ŧ', 198: 'Ũ', 199: 'ũ', 200: 'Ū', 201: 'ū', 202: 'Ŭ', 203: 'ŭ', 204: 'Ů', 205: 'ů', 206: 'Ű', 207: 'ű', 208: 'Ų', 209: 'ų', 210: 'Ŵ', 211: 'ŵ', 212: 'Ŷ', 213: 'ŷ', 214: 'Ÿ', 215: 'Ź', 216: 'ź', 217: 'Ż', 218: 'ż', 219: 'Ž', 220: 'ž', 221: 'ſ', 222: 'ƀ', 223: 'Ɓ', 224: 'Ƃ', 225: 'ƃ', 226: 'Ƅ', 227: 'ƅ', 228: 'Ɔ', 229: 'Ƈ', 230: 'ƈ', 231: 'Ɖ', 232: 'Ɗ', 233: 'Ƌ', 234: 'ƌ', 235: 'ƍ', 236: 'Ǝ', 237: 'Ə', 238: 'Ɛ', 239: 'Ƒ', 240: 'ƒ', 241: 'Ɠ', 242: 'Ɣ', 243: 'ƕ', 244: 'Ɩ', 245: 'Ɨ', 246: 'Ƙ', 247: 'ƙ', 248: 'ƚ', 249: 'ƛ', 250: 'Ɯ', 251: 'Ɲ', 252: 'ƞ', 253: 'Ɵ', 254: 'Ơ', 255: 'ơ', 256: 'Ƣ', 257: 'ƣ', 258: 'Ƥ', 259: 'ƥ', 260: 'Ʀ', 261: 'Ƨ', 262: 'ƨ', 263: 'Ʃ', 264: 'ƪ', 265: 'ƫ', 266: 'Ƭ', 267: 'ƭ', 268: 'Ʈ', 269: 'Ư', 270: 'ư', 271: 'Ʊ', 272: 'Ʋ', 273: 'Ƴ', 274: 'ƴ', 275: 'Ƶ', 276: 'ƶ', 277: 'Ʒ', 278: 'Ƹ', 279: 'ƹ', 280: 'ƺ', 281: 'ƻ', 282: 'Ƽ', 283: 'ƽ', 284: 'ƾ', 285: 'ƿ', 286: 'ǀ', 287: 'ǁ', 288: 'ǂ', 289: 'ǃ', 290: 'Ǆ', 291: 'ǅ', 292: 'ǆ', 293: 'Ǉ', 294: 'ǈ', 295: 'ǉ', 296: 'Ǌ', 297: 'ǋ', 298: 'ǌ', 299: 'Ǎ', 300: 'ǎ', 301: 'Ǐ', 302: 'ǐ', 303: 'Ǒ', 304: 'ǒ', 305: 'Ǔ', 306: 'ǔ', 307: 'Ǖ', 308: 'ǖ', 309: 'Ǘ', 310: 'ǘ', 311: 'Ǚ', 312: 'ǚ', 313: 'Ǜ', 314: 'ǜ', 315: 'ǝ', 316: 'Ǟ', 317: 'ǟ', 318: 'Ǡ', 319: 'ǡ', 320: 'Ǣ', 321: 'ǣ', 322: 'Ǥ', 323: 'ǥ', 324: 'Ǧ', 325: 'ǧ', 326: 'Ǩ', 327: 'ǩ', 328: 'Ǫ', 329: 'ǫ', 330: 'Ǭ', 331: 'ǭ', 332: 'Ǯ', 333: 'ǯ', 334: 'ǰ', 335: 'Ǳ', 336: 'ǲ', 337: 'ǳ', 338: 'Ǵ', 339: 'ǵ', 340: 'Ƕ', 341: 'Ƿ', 342: 'Ǹ', 343: 'ǹ', 344: 'Ǻ', 345: 'ǻ', 346: 'Ǽ', 347: 'ǽ', 348: 'Ǿ', 349: 'ǿ', 350: 'Ȁ', 351: 'ȁ', 352: 'Ȃ', 353: 'ȃ', 354: 'Ȅ', 355: 'ȅ', 356: 'Ȇ', 357: 'ȇ', 358: 'Ȉ', 359: 'ȉ', 360: 'Ȋ', 361: 'ȋ', 362: 'Ȍ', 363: 'ȍ', 364: 'Ȏ', 365: 'ȏ', 366: 'Ȑ', 367: 'ȑ', 368: 'Ȓ', 369: 'ȓ', 370: 'Ȕ', 371: 'ȕ', 372: 'Ȗ', 373: 'ȗ', 374: 'Ș', 375: 'ș', 376: 'Ț', 377: 'ț', 378: 'Ȝ', 379: 'ȝ', 380: 'Ȟ'}\n"
     ]
    }
   ],
   "source": [
    "ori_csvfile = open('../data/%s' % ori_eventlog, 'r')\n",
    "print('original dataset',ori_eventlog)\n",
    "spamreader = csv.reader(ori_csvfile, delimiter=',', quotechar='|')\n",
    "next(spamreader, None)  # skip the headers\n",
    "ascii_offset = 161\n",
    "lines = [] #these are all the activity seq\n",
    "timeseqs = [] #time sequences (differences between two events)\n",
    "timeseqs2 = [] #time sequences (differences between the current and first)\n",
    "\n",
    "#helper variables\n",
    "lastcase = ''\n",
    "line = ''\n",
    "firstLine = True\n",
    "times = []\n",
    "times2 = []\n",
    "numlines = 0\n",
    "casestarttime = None\n",
    "lasteventtime = None\n",
    "for row in spamreader: #the rows are \"CaseID,ActivityID,CompleteTimestamp\"\n",
    "    t = datetime.strptime(row[2], \"%Y-%m-%d %H:%M:%S\") #creates a datetime object from row[2]\n",
    "    if row[0]!=lastcase:  #'lastcase' is to save the last executed case for the loop\n",
    "        casestarttime = t\n",
    "        lasteventtime = t\n",
    "        lastcase = row[0]\n",
    "        if not firstLine:\n",
    "            lines.append(line)\n",
    "            timeseqs.append(times)\n",
    "            timeseqs2.append(times2)\n",
    "        line = ''\n",
    "        times = []\n",
    "        times2 = []\n",
    "        numlines+=1\n",
    "    line+=chr(int(row[1])+ascii_offset)\n",
    "    timesincelastevent = t - lasteventtime\n",
    "    timesincecasestart = t - casestarttime\n",
    "    timediff = 86400 * timesincelastevent.days + timesincelastevent.seconds  #time b/t current and last event\n",
    "    timediff2 = 86400 * timesincecasestart.days + timesincecasestart.seconds #time b/t current and starting event\n",
    "    times.append(timediff)\n",
    "    times2.append(timediff2)\n",
    "    lasteventtime = t\n",
    "    firstLine = False\n",
    "# add last case\n",
    "lines.append(line)\n",
    "timeseqs.append(times)\n",
    "timeseqs2.append(times2)\n",
    "numlines+=1\n",
    "step = 1\n",
    "sentences = []\n",
    "softness = 0\n",
    "next_chars = []\n",
    "lines = list(map(lambda x: x+ '!',lines)) #add a delimiter symbol '!' to the end of each line\n",
    "maxlen = max(map(lambda x: len(x),lines)) #find maximum line size\n",
    "print('maxlen:',maxlen)\n",
    "# next lines here to get all possible characters for events and annotate them with numbers\n",
    "chars = list(map(lambda x: set(x),lines))\n",
    "chars = list(set().union(*chars))\n",
    "chars.sort()\n",
    "target_chars = copy.copy(chars)\n",
    "if '!' in chars:\n",
    "    chars.remove('!')\n",
    "print('total chars: {}, target chars: {}'.format(len(chars), len(target_chars)))\n",
    "#get the target chars from the training set\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "target_char_indices = dict((c, i) for i, c in enumerate(target_chars))\n",
    "target_indices_char = dict((i, c) for i, c in enumerate(target_chars))\n",
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab23378",
   "metadata": {},
   "source": [
    "# 2.Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "027e6f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open('../data/%s' % eventlog, 'r')\n",
    "spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "next(spamreader, None)  # skip the headers\n",
    "ascii_offset = 161\n",
    "lines = [] #these are all the activity seq\n",
    "timeseqs = [] #time sequences (differences between two events)\n",
    "timeseqs2 = [] #time sequences (differences between the current and first)\n",
    "\n",
    "#helper variables\n",
    "lastcase = ''\n",
    "line = ''\n",
    "firstLine = True\n",
    "times = []\n",
    "times2 = []\n",
    "numlines = 0\n",
    "casestarttime = None\n",
    "lasteventtime = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32e1e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in spamreader: #the rows are \"CaseID,ActivityID,CompleteTimestamp\"\n",
    "    t = datetime.strptime(row[2], \"%Y-%m-%d %H:%M:%S\") #creates a datetime object from row[2]\n",
    "    if row[0]!=lastcase:  #'lastcase' is to save the last executed case for the loop\n",
    "        casestarttime = t\n",
    "        lasteventtime = t\n",
    "        lastcase = row[0]\n",
    "        if not firstLine:\n",
    "            lines.append(line)\n",
    "            timeseqs.append(times)\n",
    "            timeseqs2.append(times2)\n",
    "        line = ''\n",
    "        times = []\n",
    "        times2 = []\n",
    "        numlines+=1\n",
    "    line+=chr(int(row[1])+ascii_offset)\n",
    "    timesincelastevent = t - lasteventtime\n",
    "    timesincecasestart = t - casestarttime\n",
    "    timediff = 86400 * timesincelastevent.days + timesincelastevent.seconds  #time b/t current and last event\n",
    "    timediff2 = 86400 * timesincecasestart.days + timesincecasestart.seconds #time b/t current and starting event\n",
    "    times.append(timediff)\n",
    "    times2.append(timediff2)\n",
    "    lasteventtime = t\n",
    "    firstLine = False\n",
    "\n",
    "# add last case\n",
    "lines.append(line)\n",
    "timeseqs.append(times)\n",
    "timeseqs2.append(times2)\n",
    "numlines+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7048d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divisor: 186908.12533381264\n",
      "divisor2: 5159390.008756163\n"
     ]
    }
   ],
   "source": [
    "#average time between events\n",
    "divisor = np.mean([item for sublist in timeseqs for item in sublist]) \n",
    "print('divisor: {}'.format(divisor))\n",
    "#average time between current and starting events\n",
    "divisor2 = np.mean([item for sublist in timeseqs2 for item in sublist]) \n",
    "print('divisor2: {}'.format(divisor2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5cb884",
   "metadata": {},
   "source": [
    "# 3. Feature Enginnering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59bc4801",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open('../data/%s' % eventlog, 'r')\n",
    "spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "next(spamreader, None)  # skip the headers\n",
    "lastcase = ''\n",
    "line = ''\n",
    "firstLine = True\n",
    "lines = []\n",
    "timeseqs = []\n",
    "timeseqs2 = []\n",
    "timeseqs3 = []\n",
    "timeseqs4 = []\n",
    "times = []\n",
    "times2 = []\n",
    "times3 = []\n",
    "times4 = []\n",
    "numlines = 0\n",
    "casestarttime = None\n",
    "lasteventtime = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5147c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in spamreader:\n",
    "    t = time.strptime(row[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "    if row[0]!=lastcase:\n",
    "        casestarttime = t\n",
    "        lasteventtime = t\n",
    "        lastcase = row[0]\n",
    "        if not firstLine:\n",
    "            lines.append(line)\n",
    "            timeseqs.append(times)\n",
    "            timeseqs2.append(times2)\n",
    "            timeseqs3.append(times3)\n",
    "            timeseqs4.append(times4)\n",
    "        line = ''\n",
    "        times = []\n",
    "        times2 = []\n",
    "        times3 = []\n",
    "        times4 = []\n",
    "        numlines+=1\n",
    "    line+=chr(int(row[1])+ascii_offset)\n",
    "    timesincelastevent = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(lasteventtime))\n",
    "    timesincecasestart = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(casestarttime))\n",
    "    midnight = datetime.fromtimestamp(time.mktime(t)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    timesincemidnight = datetime.fromtimestamp(time.mktime(t))-midnight\n",
    "    timediff = 86400 * timesincelastevent.days + timesincelastevent.seconds\n",
    "    timediff2 = 86400 * timesincecasestart.days + timesincecasestart.seconds\n",
    "    timediff3 = timesincemidnight.seconds #this leaves only time even occurred after midnight\n",
    "    timediff4 = datetime.fromtimestamp(time.mktime(t)).weekday() #day of the week\n",
    "    times.append(timediff)\n",
    "    times2.append(timediff2)\n",
    "    times3.append(timediff3)\n",
    "    times4.append(timediff4)\n",
    "    lasteventtime = t\n",
    "    firstLine = False\n",
    "\n",
    "# add last case\n",
    "lines.append(line)\n",
    "timeseqs.append(times)\n",
    "timeseqs2.append(times2)\n",
    "timeseqs3.append(times3)\n",
    "timeseqs4.append(times4)\n",
    "numlines+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7714ebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold 1\n",
    "elems_per_fold = int(round(numlines/3)) #calculate the number of elements per fold\n",
    "fold1 = lines[:elems_per_fold]\n",
    "fold1_t = timeseqs[:elems_per_fold]\n",
    "fold1_t2 = timeseqs2[:elems_per_fold]\n",
    "fold1_t3 = timeseqs3[:elems_per_fold]\n",
    "fold1_t4 = timeseqs4[:elems_per_fold]\n",
    "        \n",
    "# fold 2\n",
    "fold2 = lines[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t = timeseqs[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t2 = timeseqs2[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t3 = timeseqs3[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t4 = timeseqs4[elems_per_fold:2*elems_per_fold]\n",
    "        \n",
    "# fold 3\n",
    "fold3 = lines[2*elems_per_fold:]\n",
    "fold3_t = timeseqs[2*elems_per_fold:]\n",
    "fold3_t2 = timeseqs2[2*elems_per_fold:]\n",
    "fold3_t3 = timeseqs3[2*elems_per_fold:]\n",
    "fold3_t4 = timeseqs4[2*elems_per_fold:]\n",
    "\n",
    "lines = fold1 + fold2\n",
    "lines_t = fold1_t + fold2_t\n",
    "lines_t2 = fold1_t2 + fold2_t2\n",
    "lines_t3 = fold1_t3 + fold2_t3\n",
    "lines_t4 = fold1_t4 + fold2_t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e359f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 24600\n"
     ]
    }
   ],
   "source": [
    "step = 1\n",
    "sentences = []\n",
    "softness = 0\n",
    "next_chars = []\n",
    "lines = list(map(lambda x: x+'!', lines))\n",
    "\n",
    "sentences_t = []\n",
    "sentences_t2 = []\n",
    "sentences_t3 = []\n",
    "sentences_t4 = []\n",
    "next_chars_t = []\n",
    "next_chars_t2 = []\n",
    "next_chars_t3 = []\n",
    "next_chars_t4 = []\n",
    "\n",
    "for line, line_t, line_t2, line_t3, line_t4 in zip(lines, lines_t, lines_t2, lines_t3, lines_t4):\n",
    "    for i in range(0, len(line), step):\n",
    "        if i==0:\n",
    "            continue\n",
    "\n",
    "        #we add iteratively, first symbol of the line, then two first, three...\n",
    "        sentences.append(line[0: i])\n",
    "        sentences_t.append(line_t[0:i])\n",
    "        sentences_t2.append(line_t2[0:i])\n",
    "        sentences_t3.append(line_t3[0:i])\n",
    "        sentences_t4.append(line_t4[0:i])\n",
    "        next_chars.append(line[i])\n",
    "\n",
    "        if i==len(line)-1: # special case to deal time of end character\n",
    "            next_chars_t.append(0)\n",
    "            next_chars_t2.append(0)\n",
    "            next_chars_t3.append(0)\n",
    "            next_chars_t4.append(0)\n",
    "        else:\n",
    "            next_chars_t.append(line_t[i])\n",
    "            next_chars_t2.append(line_t2[i])\n",
    "            next_chars_t3.append(line_t3[i])\n",
    "            next_chars_t4.append(line_t4[i])\n",
    "\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d239d0a3",
   "metadata": {},
   "source": [
    "# 4. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "928f529a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "num features: 386\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "num_features = len(chars)+5\n",
    "print('num features: {}'.format(num_features))\n",
    "X = np.zeros((len(sentences), maxlen, num_features), dtype=np.float32)\n",
    "y_a = np.zeros((len(sentences), len(target_chars)), dtype=np.float32)\n",
    "y_t = np.zeros((len(sentences)), dtype=np.float32)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    leftpad = maxlen-len(sentence)\n",
    "    next_t = next_chars_t[i]\n",
    "    sentence_t = sentences_t[i]\n",
    "    sentence_t2 = sentences_t2[i]\n",
    "    sentence_t3 = sentences_t3[i]\n",
    "    sentence_t4 = sentences_t4[i]\n",
    "    for t, char in enumerate(sentence):\n",
    "        multiset_abstraction = Counter(sentence[:t+1])\n",
    "        for c in chars:\n",
    "            if c==char: #this will encode present events to the right places\n",
    "                X[i, t+leftpad, char_indices[c]] = 1\n",
    "        X[i, t+leftpad, len(chars)] = t+1\n",
    "        X[i, t+leftpad, len(chars)+1] = sentence_t[t]/divisor\n",
    "        X[i, t+leftpad, len(chars)+2] = sentence_t2[t]/divisor2\n",
    "        X[i, t+leftpad, len(chars)+3] = sentence_t3[t]/86400\n",
    "        X[i, t+leftpad, len(chars)+4] = sentence_t4[t]/7\n",
    "    for c in target_chars:\n",
    "        if c==next_chars[i]:\n",
    "            y_a[i, target_char_indices[c]] = 1-softness\n",
    "        else:\n",
    "            y_a[i, target_char_indices[c]] = softness/(len(target_chars)-1)\n",
    "    y_t[i] = next_t/divisor\n",
    "    np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd1c55b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the training set to 2D\n",
    "X = X.reshape(X.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfa6699",
   "metadata": {},
   "source": [
    "# 5. Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4e5fb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcf4aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SVM\n",
    "svm = SVC(C=0.1, random_state=42)\n",
    "#svm = SVC(random_state=42)\n",
    "# Make it a Multilabel classifier using Label Powerset transformation\n",
    "multilabel_classifier = LabelPowerset(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca5e3873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters for random search\n",
    "param_dist = {\n",
    "    'classifier__C': [0.1, 1, 10, 20],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16e49e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random search object\n",
    "random_search = RandomizedSearchCV(multilabel_classifier, param_distributions=param_dist, \n",
    "                                   scoring='accuracy', cv=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2a78367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I541451\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END ..................................classifier__C=0.1; total time=   6.7s\n",
      "[CV] END ..................................classifier__C=0.1; total time=   6.1s\n",
      "[CV] END ..................................classifier__C=0.1; total time=   6.1s\n",
      "[CV] END ..................................classifier__C=0.1; total time=   6.4s\n",
      "[CV] END ..................................classifier__C=0.1; total time=   8.5s\n",
      "[CV] END ....................................classifier__C=1; total time=   7.0s\n",
      "[CV] END ....................................classifier__C=1; total time=   7.0s\n",
      "[CV] END ....................................classifier__C=1; total time=   7.5s\n",
      "[CV] END ....................................classifier__C=1; total time=  11.3s\n",
      "[CV] END ....................................classifier__C=1; total time=  10.9s\n",
      "[CV] END ...................................classifier__C=10; total time=  10.5s\n",
      "[CV] END ...................................classifier__C=10; total time=   9.0s\n",
      "[CV] END ...................................classifier__C=10; total time=   8.6s\n",
      "[CV] END ...................................classifier__C=10; total time=  10.2s\n",
      "[CV] END ...................................classifier__C=10; total time=  12.1s\n",
      "[CV] END ...................................classifier__C=20; total time=   9.2s\n",
      "[CV] END ...................................classifier__C=20; total time=  10.3s\n",
      "[CV] END ...................................classifier__C=20; total time=  10.4s\n",
      "[CV] END ...................................classifier__C=20; total time=   7.6s\n",
      "[CV] END ...................................classifier__C=20; total time=   6.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=LabelPowerset(classifier=SVC(C=0.1,\n",
       "                                                          random_state=42),\n",
       "                                           require_dense=[True, True]),\n",
       "                   param_distributions={'classifier__C': [0.1, 1, 10, 20]},\n",
       "                   scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the data to the random search object\n",
    "random_search.fit(X, y_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf41adfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__C': 10} LabelPowerset(classifier=SVC(C=10, random_state=42), require_dense=[True, True])\n"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters and model\n",
    "best_params = random_search.best_params_\n",
    "best_model = random_search .best_estimator_\n",
    "print(best_params,best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "308835b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=multilabel_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8cccb633-aa97-42e3-8479-afdcd0f84dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(C=0.1, random_state=42)\n",
    "multilabel_classifier = LabelPowerset(svm)\n",
    "best_model=multilabel_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c52c561",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_a\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\skmultilearn\\problem_transform\\lp.py:140\u001b[0m, in \u001b[0;36mLabelPowerset.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m\"\"\"Fits classifier to training data\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m.. note :: Input matrices are converted to sparse format internally if a numpy representation is passed\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    137\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_input_format(\n\u001b[0;32m    138\u001b[0m     X, sparse_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m'\u001b[39m, enforce_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_input_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:238\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;66;03m# var = E[X^2] - E[X]^2 if sparse\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m         X_var \u001b[38;5;241m=\u001b[39m (X\u001b[38;5;241m.\u001b[39mmultiply(X))\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m-\u001b[39m (X\u001b[38;5;241m.\u001b[39mmean()) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m X_var) \u001b[38;5;28;01mif\u001b[39;00m X_var \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:232\u001b[0m, in \u001b[0;36m_var\u001b[1;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[0;32m    227\u001b[0m     arrmean \u001b[38;5;241m=\u001b[39m arrmean \u001b[38;5;241m/\u001b[39m rcount\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# Compute sum of squared deviations from mean\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Note that x may not be inexact and that we need it to be an array,\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# not a scalar.\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m x \u001b[38;5;241m=\u001b[39m asanyarray(\u001b[43marr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43marrmean\u001b[49m)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, (nt\u001b[38;5;241m.\u001b[39mfloating, nt\u001b[38;5;241m.\u001b[39minteger)):\n\u001b[0;32m    235\u001b[0m     x \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mmultiply(x, x, out\u001b[38;5;241m=\u001b[39mx)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model.fit(X, y_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f30c5975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output_files/models/helpdesk_SVM_best_model.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model with the best hyperparameters\n",
    "joblib.dump(best_model, f'output_files/models/{eventlog_name}_SVM_best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20abd07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4830ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42811a29-1bbf-4bda-b927-6fc0cdb1a5e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e250ea4-8b41-49d4-82ce-fe8855802f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
