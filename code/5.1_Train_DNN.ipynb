{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e0a8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from collections import Counter\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "from datetime import datetime,timedelta\n",
    "from math import log, sqrt\n",
    "import pandas as pd\n",
    "import distance\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from jellyfish._jellyfish import damerau_levenshtein_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df68fe",
   "metadata": {},
   "source": [
    "# 1.Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ddbfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventlog = \"preprocessed_bpi13_lowV.csv\"\n",
    "eventlog_name = \"bpi13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b969382",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open('../data/%s' % eventlog, 'r')\n",
    "spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "next(spamreader, None)  # skip the headers\n",
    "ascii_offset = 161"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab23378",
   "metadata": {},
   "source": [
    "# 2.Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "027e6f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [] #these are all the activity seq\n",
    "timeseqs = [] #time sequences (differences between two events)\n",
    "timeseqs2 = [] #time sequences (differences between the current and first)\n",
    "\n",
    "#helper variables\n",
    "lastcase = ''\n",
    "line = ''\n",
    "firstLine = True\n",
    "times = []\n",
    "times2 = []\n",
    "numlines = 0\n",
    "casestarttime = None\n",
    "lasteventtime = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32e1e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in spamreader: #the rows are \"CaseID,ActivityID,CompleteTimestamp\"\n",
    "    t = datetime.strptime(row[2], \"%Y-%m-%d %H:%M:%S\") #creates a datetime object from row[2]\n",
    "    if row[0]!=lastcase:  #'lastcase' is to save the last executed case for the loop\n",
    "        casestarttime = t\n",
    "        lasteventtime = t\n",
    "        lastcase = row[0]\n",
    "        if not firstLine:\n",
    "            lines.append(line)\n",
    "            timeseqs.append(times)\n",
    "            timeseqs2.append(times2)\n",
    "        line = ''\n",
    "        times = []\n",
    "        times2 = []\n",
    "        numlines+=1\n",
    "    line+=chr(int(row[1])+ascii_offset)\n",
    "    timesincelastevent = t - lasteventtime\n",
    "    timesincecasestart = t - casestarttime\n",
    "    timediff = 86400 * timesincelastevent.days + timesincelastevent.seconds  #time b/t current and last event\n",
    "    timediff2 = 86400 * timesincecasestart.days + timesincecasestart.seconds #time b/t current and starting event\n",
    "    times.append(timediff)\n",
    "    times2.append(timediff2)\n",
    "    lasteventtime = t\n",
    "    firstLine = False\n",
    "\n",
    "# add last case\n",
    "lines.append(line)\n",
    "timeseqs.append(times)\n",
    "timeseqs2.append(times2)\n",
    "numlines+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91178c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of accessing processed data\n",
    "#print(lines)\n",
    "#print(timeseqs)\n",
    "#print(timeseqs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7048d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divisor: 210915.5199854121\n",
      "divisor2: 409874.9012399708\n"
     ]
    }
   ],
   "source": [
    "#average time between events\n",
    "divisor = np.mean([item for sublist in timeseqs for item in sublist]) \n",
    "print('divisor: {}'.format(divisor))\n",
    "#average time between current and starting events\n",
    "divisor2 = np.mean([item for sublist in timeseqs2 for item in sublist]) \n",
    "print('divisor2: {}'.format(divisor2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57247802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate training data into 3 parts\n",
    "elems_per_fold = int(round(numlines/3)) #calculate the number of elements per fold\n",
    "# fist 1/3 elements and their calculated time features\n",
    "fold1 = lines[:elems_per_fold]\n",
    "fold1_t = timeseqs[:elems_per_fold]\n",
    "fold1_t2 = timeseqs2[:elems_per_fold]\n",
    "# second 1/3 elements and their calculated time features\n",
    "fold2 = lines[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t = timeseqs[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t2 = timeseqs2[elems_per_fold:2*elems_per_fold]\n",
    "# last 1/3 elements and their calculated time features\n",
    "fold3 = lines[2*elems_per_fold:]\n",
    "fold3_t = timeseqs[2*elems_per_fold:]\n",
    "fold3_t2 = timeseqs2[2*elems_per_fold:]\n",
    "\n",
    "#consider only fist and second part as training set, leave away fold3 for now\n",
    "lines = fold1 + fold2\n",
    "lines_t = fold1_t + fold2_t\n",
    "lines_t2 = fold1_t2 + fold2_t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83fbe20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "sentences = []\n",
    "softness = 0\n",
    "next_chars = []\n",
    "lines = list(map(lambda x: x+ '!',lines)) #add a delimiter symbol '!' to the end of each line\n",
    "maxlen = max(map(lambda x: len(x),lines)) #find maximum line size\n",
    "\n",
    "# next lines here to get all possible characters for events and annotate them with numbers\n",
    "chars = list(map(lambda x: set(x),lines))\n",
    "chars = list(set().union(*chars))\n",
    "chars.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea278822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 9, target chars: 10\n"
     ]
    }
   ],
   "source": [
    "target_chars = copy.copy(chars)\n",
    "\n",
    "if '!' in chars:\n",
    "    chars.remove('!')\n",
    "print('total chars: {}, target chars: {}'.format(len(chars), len(target_chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "859f59f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '¢', 1: '£', 2: '¤', 3: '¥', 4: '¦', 5: '§', 6: '¨', 7: '©', 8: 'ª'}\n"
     ]
    }
   ],
   "source": [
    "#get the target chars from the training set\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "target_char_indices = dict((c, i) for i, c in enumerate(target_chars))\n",
    "target_indices_char = dict((i, c) for i, c in enumerate(target_chars))\n",
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5cb884",
   "metadata": {},
   "source": [
    "# 3. Feature Enginnering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59bc4801",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open('../data/%s' % eventlog, 'r')\n",
    "spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "next(spamreader, None)  # skip the headers\n",
    "lastcase = ''\n",
    "line = ''\n",
    "firstLine = True\n",
    "lines = []\n",
    "timeseqs = []\n",
    "timeseqs2 = []\n",
    "timeseqs3 = []\n",
    "timeseqs4 = []\n",
    "times = []\n",
    "times2 = []\n",
    "times3 = []\n",
    "times4 = []\n",
    "numlines = 0\n",
    "casestarttime = None\n",
    "lasteventtime = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5147c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in spamreader:\n",
    "    t = time.strptime(row[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "    if row[0]!=lastcase:\n",
    "        casestarttime = t\n",
    "        lasteventtime = t\n",
    "        lastcase = row[0]\n",
    "        if not firstLine:\n",
    "            lines.append(line)\n",
    "            timeseqs.append(times)\n",
    "            timeseqs2.append(times2)\n",
    "            timeseqs3.append(times3)\n",
    "            timeseqs4.append(times4)\n",
    "        line = ''\n",
    "        times = []\n",
    "        times2 = []\n",
    "        times3 = []\n",
    "        times4 = []\n",
    "        numlines+=1\n",
    "    line+=chr(int(row[1])+ascii_offset)\n",
    "    timesincelastevent = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(lasteventtime))\n",
    "    timesincecasestart = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(casestarttime))\n",
    "    midnight = datetime.fromtimestamp(time.mktime(t)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    timesincemidnight = datetime.fromtimestamp(time.mktime(t))-midnight\n",
    "    timediff = 86400 * timesincelastevent.days + timesincelastevent.seconds\n",
    "    timediff2 = 86400 * timesincecasestart.days + timesincecasestart.seconds\n",
    "    timediff3 = timesincemidnight.seconds #this leaves only time even occurred after midnight\n",
    "    timediff4 = datetime.fromtimestamp(time.mktime(t)).weekday() #day of the week\n",
    "    times.append(timediff)\n",
    "    times2.append(timediff2)\n",
    "    times3.append(timediff3)\n",
    "    times4.append(timediff4)\n",
    "    lasteventtime = t\n",
    "    firstLine = False\n",
    "\n",
    "# add last case\n",
    "lines.append(line)\n",
    "timeseqs.append(times)\n",
    "timeseqs2.append(times2)\n",
    "timeseqs3.append(times3)\n",
    "timeseqs4.append(times4)\n",
    "numlines+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7714ebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold 1\n",
    "elems_per_fold = int(round(numlines/3)) #calculate the number of elements per fold\n",
    "fold1 = lines[:elems_per_fold]\n",
    "fold1_t = timeseqs[:elems_per_fold]\n",
    "fold1_t2 = timeseqs2[:elems_per_fold]\n",
    "fold1_t3 = timeseqs3[:elems_per_fold]\n",
    "fold1_t4 = timeseqs4[:elems_per_fold]\n",
    "with open(f'output_files/folds/{eventlog_name}_fold1.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row, timeseq in zip(fold1, fold1_t):\n",
    "        spamwriter.writerow([str(s) + '#{}'.format(t) for s, t in zip(row, timeseq)])\n",
    "        \n",
    "# fold 2\n",
    "fold2 = lines[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t = timeseqs[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t2 = timeseqs2[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t3 = timeseqs3[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t4 = timeseqs4[elems_per_fold:2*elems_per_fold]\n",
    "with open(f'output_files/folds/{eventlog_name}_fold2.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row, timeseq in zip(fold2, fold2_t):\n",
    "        spamwriter.writerow([str(s) +'#{}'.format(t) for s, t in zip(row, timeseq)])\n",
    "        \n",
    "# fold 3\n",
    "fold3 = lines[2*elems_per_fold:]\n",
    "fold3_t = timeseqs[2*elems_per_fold:]\n",
    "fold3_t2 = timeseqs2[2*elems_per_fold:]\n",
    "fold3_t3 = timeseqs3[2*elems_per_fold:]\n",
    "fold3_t4 = timeseqs4[2*elems_per_fold:]\n",
    "with open(f'output_files/folds/{eventlog_name}_fold3.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row, timeseq in zip(fold3, fold3_t):\n",
    "        spamwriter.writerow([str(s) +'#{}'.format(t) for s, t in zip(row, timeseq)])\n",
    "\n",
    "lines = fold1 + fold2\n",
    "lines_t = fold1_t + fold2_t\n",
    "lines_t2 = fold1_t2 + fold2_t2\n",
    "lines_t3 = fold1_t3 + fold2_t3\n",
    "lines_t4 = fold1_t4 + fold2_t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e359f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 9181\n"
     ]
    }
   ],
   "source": [
    "step = 1\n",
    "sentences = []\n",
    "softness = 0\n",
    "next_chars = []\n",
    "lines = list(map(lambda x: x+'!', lines))\n",
    "\n",
    "sentences_t = []\n",
    "sentences_t2 = []\n",
    "sentences_t3 = []\n",
    "sentences_t4 = []\n",
    "next_chars_t = []\n",
    "next_chars_t2 = []\n",
    "next_chars_t3 = []\n",
    "next_chars_t4 = []\n",
    "\n",
    "for line, line_t, line_t2, line_t3, line_t4 in zip(lines, lines_t, lines_t2, lines_t3, lines_t4):\n",
    "    for i in range(0, len(line), step):\n",
    "        if i==0:\n",
    "            continue\n",
    "\n",
    "        #we add iteratively, first symbol of the line, then two first, three...\n",
    "        sentences.append(line[0: i])\n",
    "        sentences_t.append(line_t[0:i])\n",
    "        sentences_t2.append(line_t2[0:i])\n",
    "        sentences_t3.append(line_t3[0:i])\n",
    "        sentences_t4.append(line_t4[0:i])\n",
    "        next_chars.append(line[i])\n",
    "\n",
    "        if i==len(line)-1: # special case to deal time of end character\n",
    "            next_chars_t.append(0)\n",
    "            next_chars_t2.append(0)\n",
    "            next_chars_t3.append(0)\n",
    "            next_chars_t4.append(0)\n",
    "        else:\n",
    "            next_chars_t.append(line_t[i])\n",
    "            next_chars_t2.append(line_t2[i])\n",
    "            next_chars_t3.append(line_t3[i])\n",
    "            next_chars_t4.append(line_t4[i])\n",
    "\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d239d0a3",
   "metadata": {},
   "source": [
    "# 4. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "928f529a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "num features: 14\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "num_features = len(chars)+5\n",
    "print('num features: {}'.format(num_features))\n",
    "X = np.zeros((len(sentences), maxlen, num_features), dtype=np.float32)\n",
    "y_a = np.zeros((len(sentences), len(target_chars)), dtype=np.float32)\n",
    "y_t = np.zeros((len(sentences)), dtype=np.float32)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    leftpad = maxlen-len(sentence)\n",
    "    next_t = next_chars_t[i]\n",
    "    sentence_t = sentences_t[i]\n",
    "    sentence_t2 = sentences_t2[i]\n",
    "    sentence_t3 = sentences_t3[i]\n",
    "    sentence_t4 = sentences_t4[i]\n",
    "    for t, char in enumerate(sentence):\n",
    "        multiset_abstraction = Counter(sentence[:t+1])\n",
    "        for c in chars:\n",
    "            if c==char: #this will encode present events to the right places\n",
    "                X[i, t+leftpad, char_indices[c]] = 1\n",
    "        X[i, t+leftpad, len(chars)] = t+1\n",
    "        X[i, t+leftpad, len(chars)+1] = sentence_t[t]/divisor\n",
    "        X[i, t+leftpad, len(chars)+2] = sentence_t2[t]/divisor2\n",
    "        X[i, t+leftpad, len(chars)+3] = sentence_t3[t]/86400\n",
    "        X[i, t+leftpad, len(chars)+4] = sentence_t4[t]/7\n",
    "    for c in target_chars:\n",
    "        if c==next_chars[i]:\n",
    "            y_a[i, target_char_indices[c]] = 1-softness\n",
    "        else:\n",
    "            y_a[i, target_char_indices[c]] = softness/(len(target_chars)-1)\n",
    "    y_t[i] = next_t/divisor\n",
    "    np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfa6699",
   "metadata": {},
   "source": [
    "# 5. Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19430748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization,Flatten\n",
    "from tensorflow.keras.optimizers import Nadam, legacy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1815163d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "main_input = Input(shape=(maxlen, num_features), name='main_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21074ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_layer = Flatten()(main_input)\n",
    "dense1 = Dense(100, activation='relu', kernel_initializer='glorot_uniform')(flatten_layer)\n",
    "dense1 = BatchNormalization()(dense1)\n",
    "dense2 = Dense(100, activation='relu', kernel_initializer='glorot_uniform')(dense1)\n",
    "dense2 = BatchNormalization()(dense2)\n",
    "act_output = Dense(len(target_chars), activation='softmax', kernel_initializer='glorot_uniform', name='act_output')(dense2)\n",
    "time_output = Dense(1, kernel_initializer='glorot_uniform', name='time_output')(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2854386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[main_input], outputs=[act_output, time_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b14183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I541451\\Anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\nadam.py:89: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "opt = legacy.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.004, clipvalue=3)\n",
    "model.compile(loss={'act_output': 'categorical_crossentropy', 'time_output': 'mae'}, optimizer=opt)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=42)\n",
    "model_checkpoint = ModelCheckpoint('output_files/models/NN_model_{epoch:02d}-{val_loss:.2f}.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f30c5975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "490/490 - 3s - loss: 1.9766 - act_output_loss: 0.8279 - time_output_loss: 1.1487 - val_loss: 1.6228 - val_act_output_loss: 0.6075 - val_time_output_loss: 1.0153 - lr: 0.0020 - 3s/epoch - 7ms/step\n",
      "Epoch 2/500\n",
      "490/490 - 1s - loss: 1.6632 - act_output_loss: 0.6208 - time_output_loss: 1.0424 - val_loss: 1.5939 - val_act_output_loss: 0.5839 - val_time_output_loss: 1.0100 - lr: 0.0020 - 1s/epoch - 2ms/step\n",
      "Epoch 3/500\n",
      "490/490 - 1s - loss: 1.6158 - act_output_loss: 0.5982 - time_output_loss: 1.0176 - val_loss: 1.6044 - val_act_output_loss: 0.5912 - val_time_output_loss: 1.0132 - lr: 0.0020 - 1s/epoch - 2ms/step\n",
      "Epoch 4/500\n",
      "490/490 - 1s - loss: 1.6001 - act_output_loss: 0.5903 - time_output_loss: 1.0098 - val_loss: 1.5765 - val_act_output_loss: 0.5711 - val_time_output_loss: 1.0054 - lr: 0.0020 - 1s/epoch - 2ms/step\n",
      "Epoch 5/500\n",
      "490/490 - 1s - loss: 1.5898 - act_output_loss: 0.5843 - time_output_loss: 1.0055 - val_loss: 1.5712 - val_act_output_loss: 0.5740 - val_time_output_loss: 0.9971 - lr: 0.0020 - 1s/epoch - 3ms/step\n",
      "Epoch 6/500\n",
      "490/490 - 1s - loss: 1.5775 - act_output_loss: 0.5782 - time_output_loss: 0.9993 - val_loss: 1.5378 - val_act_output_loss: 0.5665 - val_time_output_loss: 0.9713 - lr: 0.0020 - 1s/epoch - 2ms/step\n",
      "Epoch 7/500\n",
      "490/490 - 1s - loss: 1.5772 - act_output_loss: 0.5773 - time_output_loss: 0.9999 - val_loss: 1.5654 - val_act_output_loss: 0.5799 - val_time_output_loss: 0.9855 - lr: 0.0020 - 1s/epoch - 2ms/step\n",
      "Epoch 8/500\n",
      "490/490 - 1s - loss: 1.5706 - act_output_loss: 0.5734 - time_output_loss: 0.9972 - val_loss: 1.5361 - val_act_output_loss: 0.5623 - val_time_output_loss: 0.9738 - lr: 0.0020 - 1s/epoch - 3ms/step\n",
      "Epoch 9/500\n",
      "490/490 - 1s - loss: 1.5650 - act_output_loss: 0.5704 - time_output_loss: 0.9945 - val_loss: 1.5750 - val_act_output_loss: 0.5726 - val_time_output_loss: 1.0023 - lr: 0.0020 - 1s/epoch - 2ms/step\n",
      "Epoch 10/500\n",
      "490/490 - 1s - loss: 1.5622 - act_output_loss: 0.5709 - time_output_loss: 0.9912 - val_loss: 1.5340 - val_act_output_loss: 0.5670 - val_time_output_loss: 0.9670 - lr: 0.0020 - 1s/epoch - 2ms/step\n",
      "Epoch 11/500\n",
      "490/490 - 1s - loss: 1.5588 - act_output_loss: 0.5665 - time_output_loss: 0.9923 - val_loss: 1.5266 - val_act_output_loss: 0.5712 - val_time_output_loss: 0.9554 - lr: 0.0020 - 1s/epoch - 2ms/step\n",
      "Epoch 12/500\n",
      "490/490 - 1s - loss: 1.5549 - act_output_loss: 0.5677 - time_output_loss: 0.9872 - val_loss: 1.5308 - val_act_output_loss: 0.5678 - val_time_output_loss: 0.9630 - lr: 0.0020 - 1s/epoch - 2ms/step\n",
      "Epoch 13/500\n",
      "490/490 - 1s - loss: 1.5479 - act_output_loss: 0.5612 - time_output_loss: 0.9867 - val_loss: 1.5326 - val_act_output_loss: 0.5668 - val_time_output_loss: 0.9658 - lr: 0.0020 - 1s/epoch - 2ms/step\n",
      "Epoch 14/500\n",
      "490/490 - 1s - loss: 1.5480 - act_output_loss: 0.5643 - time_output_loss: 0.9838 - val_loss: 1.5567 - val_act_output_loss: 0.5832 - val_time_output_loss: 0.9734 - lr: 0.0020 - 1s/epoch - 2ms/step\n",
      "Epoch 15/500\n",
      "490/490 - 1s - loss: 1.5483 - act_output_loss: 0.5638 - time_output_loss: 0.9845 - val_loss: 1.5385 - val_act_output_loss: 0.5744 - val_time_output_loss: 0.9641 - lr: 0.0020 - 815ms/epoch - 2ms/step\n",
      "Epoch 16/500\n",
      "490/490 - 1s - loss: 1.5469 - act_output_loss: 0.5588 - time_output_loss: 0.9881 - val_loss: 1.5541 - val_act_output_loss: 0.5763 - val_time_output_loss: 0.9778 - lr: 0.0020 - 698ms/epoch - 1ms/step\n",
      "Epoch 17/500\n",
      "490/490 - 1s - loss: 1.5423 - act_output_loss: 0.5607 - time_output_loss: 0.9816 - val_loss: 1.5288 - val_act_output_loss: 0.5679 - val_time_output_loss: 0.9609 - lr: 0.0020 - 701ms/epoch - 1ms/step\n",
      "Epoch 18/500\n",
      "490/490 - 1s - loss: 1.5453 - act_output_loss: 0.5611 - time_output_loss: 0.9842 - val_loss: 1.5507 - val_act_output_loss: 0.5892 - val_time_output_loss: 0.9615 - lr: 0.0020 - 748ms/epoch - 2ms/step\n",
      "Epoch 19/500\n",
      "490/490 - 1s - loss: 1.5403 - act_output_loss: 0.5570 - time_output_loss: 0.9833 - val_loss: 1.5419 - val_act_output_loss: 0.5789 - val_time_output_loss: 0.9630 - lr: 0.0020 - 751ms/epoch - 2ms/step\n",
      "Epoch 20/500\n",
      "490/490 - 1s - loss: 1.5351 - act_output_loss: 0.5488 - time_output_loss: 0.9863 - val_loss: 1.5292 - val_act_output_loss: 0.5691 - val_time_output_loss: 0.9602 - lr: 0.0020 - 733ms/epoch - 1ms/step\n",
      "Epoch 21/500\n",
      "490/490 - 1s - loss: 1.5376 - act_output_loss: 0.5556 - time_output_loss: 0.9820 - val_loss: 1.5263 - val_act_output_loss: 0.5621 - val_time_output_loss: 0.9641 - lr: 0.0020 - 743ms/epoch - 2ms/step\n",
      "Epoch 22/500\n",
      "490/490 - 1s - loss: 1.5301 - act_output_loss: 0.5513 - time_output_loss: 0.9788 - val_loss: 1.5262 - val_act_output_loss: 0.5682 - val_time_output_loss: 0.9579 - lr: 0.0020 - 745ms/epoch - 2ms/step\n",
      "Epoch 23/500\n",
      "490/490 - 1s - loss: 1.5381 - act_output_loss: 0.5503 - time_output_loss: 0.9878 - val_loss: 1.5334 - val_act_output_loss: 0.5689 - val_time_output_loss: 0.9645 - lr: 0.0020 - 711ms/epoch - 1ms/step\n",
      "Epoch 24/500\n",
      "490/490 - 1s - loss: 1.5253 - act_output_loss: 0.5459 - time_output_loss: 0.9794 - val_loss: 1.5343 - val_act_output_loss: 0.5705 - val_time_output_loss: 0.9637 - lr: 0.0020 - 745ms/epoch - 2ms/step\n",
      "Epoch 25/500\n",
      "490/490 - 1s - loss: 1.5254 - act_output_loss: 0.5486 - time_output_loss: 0.9768 - val_loss: 1.5560 - val_act_output_loss: 0.5813 - val_time_output_loss: 0.9748 - lr: 0.0020 - 714ms/epoch - 1ms/step\n",
      "Epoch 26/500\n",
      "490/490 - 1s - loss: 1.5417 - act_output_loss: 0.5534 - time_output_loss: 0.9883 - val_loss: 1.5406 - val_act_output_loss: 0.5758 - val_time_output_loss: 0.9648 - lr: 0.0020 - 726ms/epoch - 1ms/step\n",
      "Epoch 27/500\n",
      "490/490 - 1s - loss: 1.5221 - act_output_loss: 0.5438 - time_output_loss: 0.9783 - val_loss: 1.5327 - val_act_output_loss: 0.5776 - val_time_output_loss: 0.9551 - lr: 0.0020 - 688ms/epoch - 1ms/step\n",
      "Epoch 28/500\n",
      "490/490 - 1s - loss: 1.5243 - act_output_loss: 0.5436 - time_output_loss: 0.9807 - val_loss: 1.5622 - val_act_output_loss: 0.5847 - val_time_output_loss: 0.9775 - lr: 0.0020 - 687ms/epoch - 1ms/step\n",
      "Epoch 29/500\n",
      "490/490 - 1s - loss: 1.5207 - act_output_loss: 0.5464 - time_output_loss: 0.9743 - val_loss: 1.5603 - val_act_output_loss: 0.5948 - val_time_output_loss: 0.9655 - lr: 0.0020 - 716ms/epoch - 1ms/step\n",
      "Epoch 30/500\n",
      "490/490 - 1s - loss: 1.5250 - act_output_loss: 0.5448 - time_output_loss: 0.9802 - val_loss: 1.5629 - val_act_output_loss: 0.5941 - val_time_output_loss: 0.9688 - lr: 0.0020 - 830ms/epoch - 2ms/step\n",
      "Epoch 31/500\n",
      "490/490 - 1s - loss: 1.5203 - act_output_loss: 0.5420 - time_output_loss: 0.9783 - val_loss: 1.5293 - val_act_output_loss: 0.5661 - val_time_output_loss: 0.9632 - lr: 0.0020 - 788ms/epoch - 2ms/step\n",
      "Epoch 32/500\n",
      "490/490 - 1s - loss: 1.5137 - act_output_loss: 0.5375 - time_output_loss: 0.9762 - val_loss: 1.5382 - val_act_output_loss: 0.5801 - val_time_output_loss: 0.9581 - lr: 0.0020 - 864ms/epoch - 2ms/step\n",
      "Epoch 33/500\n",
      "490/490 - 1s - loss: 1.5041 - act_output_loss: 0.5309 - time_output_loss: 0.9732 - val_loss: 1.5506 - val_act_output_loss: 0.5900 - val_time_output_loss: 0.9607 - lr: 0.0010 - 812ms/epoch - 2ms/step\n",
      "Epoch 34/500\n",
      "490/490 - 1s - loss: 1.4996 - act_output_loss: 0.5288 - time_output_loss: 0.9708 - val_loss: 1.5498 - val_act_output_loss: 0.5860 - val_time_output_loss: 0.9639 - lr: 0.0010 - 900ms/epoch - 2ms/step\n",
      "Epoch 35/500\n",
      "490/490 - 1s - loss: 1.5045 - act_output_loss: 0.5328 - time_output_loss: 0.9716 - val_loss: 1.5846 - val_act_output_loss: 0.5962 - val_time_output_loss: 0.9884 - lr: 0.0010 - 837ms/epoch - 2ms/step\n",
      "Epoch 36/500\n",
      "490/490 - 1s - loss: 1.4947 - act_output_loss: 0.5241 - time_output_loss: 0.9706 - val_loss: 1.5769 - val_act_output_loss: 0.6134 - val_time_output_loss: 0.9636 - lr: 0.0010 - 725ms/epoch - 1ms/step\n",
      "Epoch 37/500\n",
      "490/490 - 1s - loss: 1.4956 - act_output_loss: 0.5269 - time_output_loss: 0.9686 - val_loss: 1.5586 - val_act_output_loss: 0.5862 - val_time_output_loss: 0.9724 - lr: 0.0010 - 754ms/epoch - 2ms/step\n",
      "Epoch 38/500\n",
      "490/490 - 1s - loss: 1.4954 - act_output_loss: 0.5243 - time_output_loss: 0.9712 - val_loss: 1.5560 - val_act_output_loss: 0.5904 - val_time_output_loss: 0.9656 - lr: 0.0010 - 766ms/epoch - 2ms/step\n",
      "Epoch 39/500\n",
      "490/490 - 1s - loss: 1.4993 - act_output_loss: 0.5276 - time_output_loss: 0.9718 - val_loss: 1.6003 - val_act_output_loss: 0.6040 - val_time_output_loss: 0.9964 - lr: 0.0010 - 835ms/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/500\n",
      "490/490 - 1s - loss: 1.4917 - act_output_loss: 0.5214 - time_output_loss: 0.9703 - val_loss: 1.5856 - val_act_output_loss: 0.6035 - val_time_output_loss: 0.9822 - lr: 0.0010 - 762ms/epoch - 2ms/step\n",
      "Epoch 41/500\n",
      "490/490 - 1s - loss: 1.4955 - act_output_loss: 0.5250 - time_output_loss: 0.9705 - val_loss: 1.6193 - val_act_output_loss: 0.6207 - val_time_output_loss: 0.9986 - lr: 0.0010 - 800ms/epoch - 2ms/step\n",
      "Epoch 42/500\n",
      "490/490 - 1s - loss: 1.4907 - act_output_loss: 0.5260 - time_output_loss: 0.9647 - val_loss: 1.5746 - val_act_output_loss: 0.6046 - val_time_output_loss: 0.9700 - lr: 0.0010 - 852ms/epoch - 2ms/step\n",
      "Epoch 43/500\n",
      "490/490 - 1s - loss: 1.4857 - act_output_loss: 0.5189 - time_output_loss: 0.9668 - val_loss: 1.5717 - val_act_output_loss: 0.6067 - val_time_output_loss: 0.9650 - lr: 5.0000e-04 - 837ms/epoch - 2ms/step\n",
      "Epoch 44/500\n",
      "490/490 - 1s - loss: 1.4836 - act_output_loss: 0.5178 - time_output_loss: 0.9658 - val_loss: 1.5627 - val_act_output_loss: 0.5985 - val_time_output_loss: 0.9642 - lr: 5.0000e-04 - 804ms/epoch - 2ms/step\n",
      "Epoch 45/500\n",
      "490/490 - 1s - loss: 1.4859 - act_output_loss: 0.5187 - time_output_loss: 0.9672 - val_loss: 1.5595 - val_act_output_loss: 0.5941 - val_time_output_loss: 0.9654 - lr: 5.0000e-04 - 796ms/epoch - 2ms/step\n",
      "Epoch 46/500\n",
      "490/490 - 1s - loss: 1.4814 - act_output_loss: 0.5136 - time_output_loss: 0.9677 - val_loss: 1.5725 - val_act_output_loss: 0.6053 - val_time_output_loss: 0.9672 - lr: 5.0000e-04 - 806ms/epoch - 2ms/step\n",
      "Epoch 47/500\n",
      "490/490 - 1s - loss: 1.4758 - act_output_loss: 0.5107 - time_output_loss: 0.9651 - val_loss: 1.5727 - val_act_output_loss: 0.6097 - val_time_output_loss: 0.9631 - lr: 5.0000e-04 - 800ms/epoch - 2ms/step\n",
      "Epoch 48/500\n",
      "490/490 - 1s - loss: 1.4720 - act_output_loss: 0.5092 - time_output_loss: 0.9628 - val_loss: 1.5853 - val_act_output_loss: 0.6140 - val_time_output_loss: 0.9713 - lr: 5.0000e-04 - 831ms/epoch - 2ms/step\n",
      "Epoch 49/500\n",
      "490/490 - 1s - loss: 1.4706 - act_output_loss: 0.5061 - time_output_loss: 0.9645 - val_loss: 1.5900 - val_act_output_loss: 0.6123 - val_time_output_loss: 0.9777 - lr: 5.0000e-04 - 872ms/epoch - 2ms/step\n",
      "Epoch 50/500\n",
      "490/490 - 1s - loss: 1.4776 - act_output_loss: 0.5127 - time_output_loss: 0.9649 - val_loss: 1.5984 - val_act_output_loss: 0.6205 - val_time_output_loss: 0.9779 - lr: 5.0000e-04 - 961ms/epoch - 2ms/step\n",
      "Epoch 51/500\n",
      "490/490 - 1s - loss: 1.4775 - act_output_loss: 0.5131 - time_output_loss: 0.9644 - val_loss: 1.5995 - val_act_output_loss: 0.6156 - val_time_output_loss: 0.9838 - lr: 5.0000e-04 - 937ms/epoch - 2ms/step\n",
      "Epoch 52/500\n",
      "490/490 - 1s - loss: 1.4761 - act_output_loss: 0.5108 - time_output_loss: 0.9653 - val_loss: 1.5806 - val_act_output_loss: 0.6147 - val_time_output_loss: 0.9659 - lr: 5.0000e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 53/500\n",
      "490/490 - 1s - loss: 1.4709 - act_output_loss: 0.5079 - time_output_loss: 0.9630 - val_loss: 1.5779 - val_act_output_loss: 0.6143 - val_time_output_loss: 0.9636 - lr: 2.5000e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 54/500\n",
      "490/490 - 1s - loss: 1.4647 - act_output_loss: 0.5081 - time_output_loss: 0.9566 - val_loss: 1.6108 - val_act_output_loss: 0.6284 - val_time_output_loss: 0.9824 - lr: 2.5000e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 55/500\n",
      "490/490 - 1s - loss: 1.4719 - act_output_loss: 0.5047 - time_output_loss: 0.9672 - val_loss: 1.5943 - val_act_output_loss: 0.6267 - val_time_output_loss: 0.9676 - lr: 2.5000e-04 - 1s/epoch - 2ms/step\n",
      "Epoch 56/500\n",
      "490/490 - 1s - loss: 1.4640 - act_output_loss: 0.5015 - time_output_loss: 0.9625 - val_loss: 1.5938 - val_act_output_loss: 0.6251 - val_time_output_loss: 0.9687 - lr: 2.5000e-04 - 1s/epoch - 3ms/step\n",
      "Epoch 57/500\n",
      "490/490 - 2s - loss: 1.4686 - act_output_loss: 0.5040 - time_output_loss: 0.9646 - val_loss: 1.6092 - val_act_output_loss: 0.6245 - val_time_output_loss: 0.9847 - lr: 2.5000e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 58/500\n",
      "490/490 - 1s - loss: 1.4663 - act_output_loss: 0.5032 - time_output_loss: 0.9630 - val_loss: 1.5838 - val_act_output_loss: 0.6214 - val_time_output_loss: 0.9624 - lr: 2.5000e-04 - 1s/epoch - 3ms/step\n",
      "Epoch 59/500\n",
      "490/490 - 1s - loss: 1.4581 - act_output_loss: 0.4985 - time_output_loss: 0.9596 - val_loss: 1.6443 - val_act_output_loss: 0.6498 - val_time_output_loss: 0.9945 - lr: 2.5000e-04 - 1s/epoch - 3ms/step\n",
      "Epoch 60/500\n",
      "490/490 - 2s - loss: 1.4579 - act_output_loss: 0.4999 - time_output_loss: 0.9579 - val_loss: 1.5959 - val_act_output_loss: 0.6244 - val_time_output_loss: 0.9715 - lr: 2.5000e-04 - 2s/epoch - 4ms/step\n",
      "Epoch 61/500\n",
      "490/490 - 2s - loss: 1.4639 - act_output_loss: 0.5052 - time_output_loss: 0.9588 - val_loss: 1.6141 - val_act_output_loss: 0.6338 - val_time_output_loss: 0.9803 - lr: 2.5000e-04 - 2s/epoch - 4ms/step\n",
      "Epoch 62/500\n",
      "490/490 - 2s - loss: 1.4609 - act_output_loss: 0.5007 - time_output_loss: 0.9602 - val_loss: 1.6008 - val_act_output_loss: 0.6257 - val_time_output_loss: 0.9751 - lr: 2.5000e-04 - 2s/epoch - 5ms/step\n",
      "Epoch 63/500\n",
      "490/490 - 2s - loss: 1.4660 - act_output_loss: 0.5033 - time_output_loss: 0.9627 - val_loss: 1.6199 - val_act_output_loss: 0.6379 - val_time_output_loss: 0.9820 - lr: 1.2500e-04 - 2s/epoch - 4ms/step\n",
      "Epoch 64/500\n",
      "490/490 - 2s - loss: 1.4651 - act_output_loss: 0.5063 - time_output_loss: 0.9588 - val_loss: 1.6091 - val_act_output_loss: 0.6306 - val_time_output_loss: 0.9785 - lr: 1.2500e-04 - 2s/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2295abefa60>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, {'act_output':y_a, 'time_output':y_t}, validation_split=0.2, verbose=2, callbacks=[early_stopping, model_checkpoint, lr_reducer], batch_size=maxlen, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1add7133",
   "metadata": {},
   "source": [
    "# 6.Make Prediction & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23f2d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divisor: 210915.5199854121\n",
      "divisor2: 409874.9012399708\n"
     ]
    }
   ],
   "source": [
    "eventlog = \"helpdesk.csv\"\n",
    "csvfile = open('../data/%s' % eventlog, 'r')\n",
    "spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "next(spamreader, None)  # skip the headers\n",
    "ascii_offset = 161\n",
    "\n",
    "lastcase = ''\n",
    "line = ''\n",
    "firstLine = True\n",
    "lines = []\n",
    "caseids = []\n",
    "timeseqs = []\n",
    "timeseqs2 = []\n",
    "times = []\n",
    "times2 = []\n",
    "numlines = 0\n",
    "casestarttime = None\n",
    "lasteventtime = None\n",
    "for row in spamreader:\n",
    "    t = time.strptime(row[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "    if row[0]!=lastcase:\n",
    "        caseids.append(row[0])\n",
    "        casestarttime = t\n",
    "        lasteventtime = t\n",
    "        lastcase = row[0]\n",
    "        if not firstLine:\n",
    "            lines.append(line)\n",
    "            timeseqs.append(times)\n",
    "            timeseqs2.append(times2)\n",
    "        line = ''\n",
    "        times = []\n",
    "        numlines+=1\n",
    "    line+=chr(int(row[1])+ascii_offset)\n",
    "    timesincelastevent = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(lasteventtime))\n",
    "    timesincecasestart = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(casestarttime))\n",
    "    timediff = 86400 * timesincelastevent.days + timesincelastevent.seconds\n",
    "    timediff2 = 86400 * timesincecasestart.days + timesincecasestart.seconds\n",
    "    times.append(timediff)\n",
    "    times2.append(timediff2)\n",
    "    lasteventtime = t\n",
    "    firstLine = False\n",
    "\n",
    "# add last case\n",
    "lines.append(line)\n",
    "timeseqs.append(times)\n",
    "timeseqs2.append(times2)\n",
    "numlines+=1\n",
    "\n",
    "#average time between events\n",
    "divisor = np.mean([item for sublist in timeseqs for item in sublist])\n",
    "print('divisor: {}'.format(divisor))\n",
    "#average time between current and starting events\n",
    "divisor2 = np.mean([item for sublist in timeseqs2 for item in sublist])\n",
    "print('divisor2: {}'.format(divisor2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05ee64a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 9, target chars: 10\n",
      "{0: '¢', 1: '£', 2: '¤', 3: '¥', 4: '¦', 5: '§', 6: '¨', 7: '©', 8: 'ª'}\n"
     ]
    }
   ],
   "source": [
    "elems_per_fold = int(round(numlines/3))\n",
    "fold1 = lines[:elems_per_fold]\n",
    "fold1_c = caseids[:elems_per_fold]\n",
    "fold1_t = timeseqs[:elems_per_fold]\n",
    "fold1_t2 = timeseqs2[:elems_per_fold]\n",
    "\n",
    "fold2 = lines[elems_per_fold:2*elems_per_fold]\n",
    "fold2_c = caseids[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t = timeseqs[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t2 = timeseqs2[elems_per_fold:2*elems_per_fold]\n",
    "\n",
    "lines = fold1 + fold2\n",
    "caseids = fold1_c + fold2_c\n",
    "lines_t = fold1_t + fold2_t\n",
    "lines_t2 = fold1_t2 + fold2_t2\n",
    "\n",
    "step = 1\n",
    "sentences = []\n",
    "softness = 0\n",
    "next_chars = []\n",
    "lines = list(map(lambda x: x+'!',lines))\n",
    "maxlen = max(map(lambda x: len(x),lines))\n",
    "\n",
    "chars = list(map(lambda x : set(x),lines))\n",
    "chars = list(set().union(*chars))\n",
    "chars.sort()\n",
    "target_chars = copy.copy(chars)\n",
    "chars.remove('!')\n",
    "print('total chars: {}, target chars: {}'.format(len(chars), len(target_chars)))\n",
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}\n",
    "target_char_indices = {c: i for i, c in enumerate(target_chars)}\n",
    "target_indices_char = {i: c for i, c in enumerate(target_chars)}\n",
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6721f165",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastcase = ''\n",
    "line = ''\n",
    "firstLine = True\n",
    "lines = []\n",
    "caseids = []\n",
    "timeseqs = []  # relative time since previous event\n",
    "timeseqs2 = [] # relative time since case start\n",
    "timeseqs3 = [] # absolute time of previous event\n",
    "times = []\n",
    "times2 = []\n",
    "times3 = []\n",
    "numlines = 0\n",
    "casestarttime = None\n",
    "lasteventtime = None\n",
    "csvfile = open('../data/%s' % eventlog, 'r')\n",
    "spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "next(spamreader, None)  # skip the headers\n",
    "for row in spamreader:\n",
    "    t = time.strptime(row[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "    if row[0]!=lastcase:\n",
    "        caseids.append(row[0])\n",
    "        casestarttime = t\n",
    "        lasteventtime = t\n",
    "        lastcase = row[0]\n",
    "        if not firstLine:        \n",
    "            lines.append(line)\n",
    "            timeseqs.append(times)\n",
    "            timeseqs2.append(times2)\n",
    "            timeseqs3.append(times3)\n",
    "        line = ''\n",
    "        times = []\n",
    "        numlines+=1\n",
    "    line+=chr(int(row[1])+ascii_offset)\n",
    "    timesincelastevent = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(lasteventtime))\n",
    "    timesincecasestart = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(casestarttime))\n",
    "    midnight = datetime.fromtimestamp(time.mktime(t)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    timesincemidnight = datetime.fromtimestamp(time.mktime(t))-midnight\n",
    "    timediff = 86400 * timesincelastevent.days + timesincelastevent.seconds\n",
    "    timediff2 = 86400 * timesincecasestart.days + timesincecasestart.seconds\n",
    "    #timediff = log(timediff+1)\n",
    "    times.append(timediff)\n",
    "    times2.append(timediff2)\n",
    "    times3.append(datetime.fromtimestamp(time.mktime(t)))\n",
    "    lasteventtime = t\n",
    "    firstLine = False\n",
    "\n",
    "# add last case\n",
    "lines.append(line)\n",
    "timeseqs.append(times)\n",
    "timeseqs2.append(times2)\n",
    "timeseqs3.append(times3)\n",
    "numlines+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dde429",
   "metadata": {},
   "source": [
    "### Using last 1/3 as test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "baa23939",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold3 = lines[2*elems_per_fold:]\n",
    "fold3_c = caseids[2*elems_per_fold:]\n",
    "fold3_t = timeseqs[2*elems_per_fold:]\n",
    "fold3_t2 = timeseqs2[2*elems_per_fold:]\n",
    "fold3_t3 = timeseqs3[2*elems_per_fold:]\n",
    "#fold3_t4 = timeseqs4[2*elems_per_fold:]\n",
    "\n",
    "lines = fold3\n",
    "caseids = fold3_c\n",
    "lines_t = fold3_t\n",
    "lines_t2 = fold3_t2\n",
    "lines_t3 = fold3_t3\n",
    "#lines_t4 = fold1_t4 + fold2_t4\n",
    "\n",
    "# set parameters\n",
    "predict_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3697eda7",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1b29ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model, set this to the model generated above\n",
    "model = load_model('output_files/models/NN_model_22-1.53.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03c43937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper functions\n",
    "# Define the function to encode the input sequence\n",
    "def encode(sentence, times, times3, maxlen=maxlen):\n",
    "    num_features = len(chars)+5\n",
    "    X = np.zeros((1, maxlen, num_features), dtype=np.float32)\n",
    "    leftpad = maxlen-len(sentence)\n",
    "    times2 = np.cumsum(times)\n",
    "    for t, char in enumerate(sentence):\n",
    "        midnight = times3[t].replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "        timesincemidnight = times3[t]-midnight\n",
    "        multiset_abstraction = Counter(sentence[:t+1])\n",
    "        for c in chars:\n",
    "            if c==char:\n",
    "                X[0, t+leftpad, char_indices[c]] = 1\n",
    "        X[0, t+leftpad, len(chars)] = t+1\n",
    "        X[0, t+leftpad, len(chars)+1] = times[t]/divisor\n",
    "        X[0, t+leftpad, len(chars)+2] = times2[t]/divisor2\n",
    "        X[0, t+leftpad, len(chars)+3] = timesincemidnight.seconds/86400\n",
    "        X[0, t+leftpad, len(chars)+4] = times3[t].weekday()/7\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1bde354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to get the predicted symbol from the output vector\n",
    "def getSymbol(predictions):\n",
    "    maxIndex = np.argmax(predictions)\n",
    "    symbol = target_indices_char[maxIndex]\n",
    "    return symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09d96e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_ahead_gt = []\n",
    "one_ahead_pred = []\n",
    "\n",
    "two_ahead_gt = []\n",
    "two_ahead_pred = []\n",
    "\n",
    "three_ahead_gt = []\n",
    "three_ahead_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5afa05fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "3\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "4\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "5\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "6\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "7\n",
      "! predicted, end case\n",
      "8\n",
      "! predicted, end case\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "with open('output_files/results/NN_next_activity_%s' % eventlog, 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow([\"CaseID\", \"Prefix length\", \"Groud truth\", \"Predicted\", \"Levenshtein\", \"Damerau\", \"Jaccard\"])\n",
    "    for prefix_size in range(2,maxlen):\n",
    "        print(prefix_size)\n",
    "        for line, caseid, times, times3 in zip(lines, caseids, lines_t, lines_t3):\n",
    "            times.append(0)\n",
    "            cropped_line = ''.join(line[:prefix_size])\n",
    "            cropped_times = times[:prefix_size]\n",
    "            cropped_times3 = times3[:prefix_size]\n",
    "            if '!' in cropped_line:\n",
    "                continue # make no prediction for this case, since this case has ended already\n",
    "            ground_truth = ''.join(line[prefix_size:prefix_size+predict_size])\n",
    "            #print(\"ground_truth:\"+ground_truth)\n",
    "            ground_truth_t = times[prefix_size:prefix_size+predict_size]\n",
    "            predicted = ''\n",
    "            predicted_t = []\n",
    "            for i in range(predict_size):\n",
    "                if len(ground_truth)<=i:\n",
    "                    continue\n",
    "                enc = encode(cropped_line, cropped_times, cropped_times3)\n",
    "                y = model.predict(enc, verbose=0)\n",
    "                y_char = y[0][0]\n",
    "                #print(y_char)\n",
    "                prediction = getSymbol(y_char)              \n",
    "                cropped_line += prediction\n",
    "                #print(\"cropped_line:\"+cropped_line)\n",
    "                \n",
    "                if prediction == '!': # end of case was just predicted, therefore, stop predicting further into the future\n",
    "                    print('! predicted, end case')\n",
    "                    break\n",
    "                predicted += prediction\n",
    "                #print(\"predicted:\" +predicted)\n",
    "            output = []\n",
    "            \n",
    "            if len(ground_truth)>0:\n",
    "                output.append(caseid)\n",
    "                output.append(prefix_size)\n",
    "                output.append(str(ground_truth).encode(\"utf-8\"))\n",
    "                output.append(str(predicted).encode(\"utf-8\"))\n",
    "                output.append(1 - distance.nlevenshtein(predicted, ground_truth))\n",
    "                dls = 1 - (damerau_levenshtein_distance(str(predicted), str(ground_truth)) / max(len(predicted),len(ground_truth)))\n",
    "                if dls<0:\n",
    "                    dls=0 # we encountered problems with Damerau-Levenshtein Similarity on some linux machines where the default character encoding of the operating system caused it to be negative, this should never be the case\n",
    "                output.append(dls)\n",
    "                output.append(1 - distance.jaccard(predicted, ground_truth))\n",
    "\n",
    "                output.append('')\n",
    "                output.append('')\n",
    "                output.append('')\n",
    "                spamwriter.writerow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1171adb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
