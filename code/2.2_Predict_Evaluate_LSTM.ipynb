{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "759077a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, SimpleRNN, Input, BatchNormalization\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0a8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from collections import Counter\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "from datetime import datetime,timedelta\n",
    "from math import log, sqrt\n",
    "import pandas as pd\n",
    "import distance\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from jellyfish._jellyfish import damerau_levenshtein_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df68fe",
   "metadata": {},
   "source": [
    "# 1.Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ddbfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventlog = \"helpdesk.csv\"\n",
    "eventlog_name = \"helpdesk\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1add7133",
   "metadata": {},
   "source": [
    "# 2.Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f2d1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divisor: 210915.5199854121\n",
      "divisor2: 409874.9012399708\n"
     ]
    }
   ],
   "source": [
    "csvfile = open('../data/%s' % eventlog, 'r')\n",
    "spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "next(spamreader, None)  # skip the headers\n",
    "ascii_offset = 161\n",
    "\n",
    "lastcase = ''\n",
    "line = ''\n",
    "firstLine = True\n",
    "lines = []\n",
    "caseids = []\n",
    "timeseqs = []\n",
    "timeseqs2 = []\n",
    "times = []\n",
    "times2 = []\n",
    "numlines = 0\n",
    "casestarttime = None\n",
    "lasteventtime = None\n",
    "for row in spamreader:\n",
    "    t = time.strptime(row[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "    if row[0]!=lastcase:\n",
    "        caseids.append(row[0])\n",
    "        casestarttime = t\n",
    "        lasteventtime = t\n",
    "        lastcase = row[0]\n",
    "        if not firstLine:\n",
    "            lines.append(line)\n",
    "            timeseqs.append(times)\n",
    "            timeseqs2.append(times2)\n",
    "        line = ''\n",
    "        times = []\n",
    "        numlines+=1\n",
    "    line+=chr(int(row[1])+ascii_offset)\n",
    "    timesincelastevent = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(lasteventtime))\n",
    "    timesincecasestart = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(casestarttime))\n",
    "    timediff = 86400 * timesincelastevent.days + timesincelastevent.seconds\n",
    "    timediff2 = 86400 * timesincecasestart.days + timesincecasestart.seconds\n",
    "    times.append(timediff)\n",
    "    times2.append(timediff2)\n",
    "    lasteventtime = t\n",
    "    firstLine = False\n",
    "\n",
    "# add last case\n",
    "lines.append(line)\n",
    "timeseqs.append(times)\n",
    "timeseqs2.append(times2)\n",
    "numlines+=1\n",
    "\n",
    "#average time between events\n",
    "divisor = np.mean([item for sublist in timeseqs for item in sublist])\n",
    "print('divisor: {}'.format(divisor))\n",
    "#average time between current and starting events\n",
    "divisor2 = np.mean([item for sublist in timeseqs2 for item in sublist])\n",
    "print('divisor2: {}'.format(divisor2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05ee64a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 9, target chars: 10\n",
      "{0: '¢', 1: '£', 2: '¤', 3: '¥', 4: '¦', 5: '§', 6: '¨', 7: '©', 8: 'ª'}\n"
     ]
    }
   ],
   "source": [
    "elems_per_fold = int(round(numlines/3))\n",
    "fold1 = lines[:elems_per_fold]\n",
    "fold1_c = caseids[:elems_per_fold]\n",
    "fold1_t = timeseqs[:elems_per_fold]\n",
    "fold1_t2 = timeseqs2[:elems_per_fold]\n",
    "\n",
    "fold2 = lines[elems_per_fold:2*elems_per_fold]\n",
    "fold2_c = caseids[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t = timeseqs[elems_per_fold:2*elems_per_fold]\n",
    "fold2_t2 = timeseqs2[elems_per_fold:2*elems_per_fold]\n",
    "\n",
    "lines = fold1 + fold2\n",
    "caseids = fold1_c + fold2_c\n",
    "lines_t = fold1_t + fold2_t\n",
    "lines_t2 = fold1_t2 + fold2_t2\n",
    "\n",
    "step = 1\n",
    "sentences = []\n",
    "softness = 0\n",
    "next_chars = []\n",
    "lines = list(map(lambda x: x+'!',lines))\n",
    "maxlen = max(map(lambda x: len(x),lines))\n",
    "\n",
    "chars = list(map(lambda x : set(x),lines))\n",
    "chars = list(set().union(*chars))\n",
    "chars.sort()\n",
    "target_chars = copy.copy(chars)\n",
    "chars.remove('!')\n",
    "print('total chars: {}, target chars: {}'.format(len(chars), len(target_chars)))\n",
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}\n",
    "target_char_indices = {c: i for i, c in enumerate(target_chars)}\n",
    "target_indices_char = {i: c for i, c in enumerate(target_chars)}\n",
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6721f165",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastcase = ''\n",
    "line = ''\n",
    "firstLine = True\n",
    "lines = []\n",
    "caseids = []\n",
    "timeseqs = []  # relative time since previous event\n",
    "timeseqs2 = [] # relative time since case start\n",
    "timeseqs3 = [] # absolute time of previous event\n",
    "times = []\n",
    "times2 = []\n",
    "times3 = []\n",
    "numlines = 0\n",
    "casestarttime = None\n",
    "lasteventtime = None\n",
    "csvfile = open('../data/%s' % eventlog, 'r')\n",
    "spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "next(spamreader, None)  # skip the headers\n",
    "for row in spamreader:\n",
    "    t = time.strptime(row[2], \"%Y-%m-%d %H:%M:%S\")\n",
    "    if row[0]!=lastcase:\n",
    "        caseids.append(row[0])\n",
    "        casestarttime = t\n",
    "        lasteventtime = t\n",
    "        lastcase = row[0]\n",
    "        if not firstLine:        \n",
    "            lines.append(line)\n",
    "            timeseqs.append(times)\n",
    "            timeseqs2.append(times2)\n",
    "            timeseqs3.append(times3)\n",
    "        line = ''\n",
    "        times = []\n",
    "        numlines+=1\n",
    "    line+=chr(int(row[1])+ascii_offset)\n",
    "    timesincelastevent = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(lasteventtime))\n",
    "    timesincecasestart = datetime.fromtimestamp(time.mktime(t))-datetime.fromtimestamp(time.mktime(casestarttime))\n",
    "    midnight = datetime.fromtimestamp(time.mktime(t)).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    timesincemidnight = datetime.fromtimestamp(time.mktime(t))-midnight\n",
    "    timediff = 86400 * timesincelastevent.days + timesincelastevent.seconds\n",
    "    timediff2 = 86400 * timesincecasestart.days + timesincecasestart.seconds\n",
    "    #timediff = log(timediff+1)\n",
    "    times.append(timediff)\n",
    "    times2.append(timediff2)\n",
    "    times3.append(datetime.fromtimestamp(time.mktime(t)))\n",
    "    lasteventtime = t\n",
    "    firstLine = False\n",
    "\n",
    "# add last case\n",
    "lines.append(line)\n",
    "timeseqs.append(times)\n",
    "timeseqs2.append(times2)\n",
    "timeseqs3.append(times3)\n",
    "numlines+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dde429",
   "metadata": {},
   "source": [
    "### Using last 1/3 as test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baa23939",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold3 = lines[2*elems_per_fold:]\n",
    "fold3_c = caseids[2*elems_per_fold:]\n",
    "fold3_t = timeseqs[2*elems_per_fold:]\n",
    "fold3_t2 = timeseqs2[2*elems_per_fold:]\n",
    "fold3_t3 = timeseqs3[2*elems_per_fold:]\n",
    "#fold3_t4 = timeseqs4[2*elems_per_fold:]\n",
    "\n",
    "lines = fold3\n",
    "caseids = fold3_c\n",
    "lines_t = fold3_t\n",
    "lines_t2 = fold3_t2\n",
    "lines_t3 = fold3_t3\n",
    "#lines_t4 = fold1_t4 + fold2_t4\n",
    "\n",
    "# set parameters\n",
    "predict_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3697eda7",
   "metadata": {},
   "source": [
    "# 3. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1b29ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model, set this to the model generated above\n",
    "model = load_model('output_files/models/LSTM_model_02-0.57.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03c43937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper functions\n",
    "# Define the function to encode the input sequence\n",
    "def encode(sentence, times, times3, maxlen=maxlen):\n",
    "    num_features = len(chars)+5\n",
    "    X = np.zeros((1, maxlen, num_features), dtype=np.float32)\n",
    "    leftpad = maxlen-len(sentence)\n",
    "    times2 = np.cumsum(times)\n",
    "    for t, char in enumerate(sentence):\n",
    "        midnight = times3[t].replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "        timesincemidnight = times3[t]-midnight\n",
    "        multiset_abstraction = Counter(sentence[:t+1])\n",
    "        for c in chars:\n",
    "            if c==char:\n",
    "                X[0, t+leftpad, char_indices[c]] = 1\n",
    "        X[0, t+leftpad, len(chars)] = t+1\n",
    "        X[0, t+leftpad, len(chars)+1] = times[t]/divisor\n",
    "        X[0, t+leftpad, len(chars)+2] = times2[t]/divisor2\n",
    "        X[0, t+leftpad, len(chars)+3] = timesincemidnight.seconds/86400\n",
    "        X[0, t+leftpad, len(chars)+4] = times3[t].weekday()/7\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1bde354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to get the predicted symbol from the output vector\n",
    "def getSymbol(predictions):\n",
    "    maxIndex = np.argmax(predictions)\n",
    "    symbol = target_indices_char[maxIndex]\n",
    "    return symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09d96e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_ahead_gt = []\n",
    "one_ahead_pred = []\n",
    "\n",
    "two_ahead_gt = []\n",
    "two_ahead_pred = []\n",
    "\n",
    "three_ahead_gt = []\n",
    "three_ahead_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5afa05fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "3\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "4\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "5\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "6\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "! predicted, end case\n",
      "7\n",
      "! predicted, end case\n",
      "8\n",
      "! predicted, end case\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "with open(f'output_files/results/{eventlog_name}_LSTM_next_activity_%s' % eventlog, 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow([\"CaseID\", \"Prefix length\", \"Groud truth\", \"Predicted\", \"Levenshtein\", \"Damerau\", \"Jaccard\"])\n",
    "    for prefix_size in range(2,maxlen):\n",
    "        print(prefix_size)\n",
    "        for line, caseid, times, times3 in zip(lines, caseids, lines_t, lines_t3):\n",
    "            times.append(0)\n",
    "            cropped_line = ''.join(line[:prefix_size])\n",
    "            cropped_times = times[:prefix_size]\n",
    "            cropped_times3 = times3[:prefix_size]\n",
    "            if '!' in cropped_line:\n",
    "                continue # make no prediction for this case, since this case has ended already\n",
    "            ground_truth = ''.join(line[prefix_size:prefix_size+predict_size])\n",
    "            #print(\"ground_truth:\"+ground_truth)\n",
    "            ground_truth_t = times[prefix_size:prefix_size+predict_size]\n",
    "            predicted = ''\n",
    "            predicted_t = []\n",
    "            for i in range(predict_size):\n",
    "                if len(ground_truth)<=i:\n",
    "                    continue\n",
    "                enc = encode(cropped_line, cropped_times, cropped_times3)\n",
    "                y = model.predict(enc, verbose=0)\n",
    "                y_char = y[0][0]\n",
    "                #print(y_char)\n",
    "                prediction = getSymbol(y_char)              \n",
    "                cropped_line += prediction\n",
    "                #print(\"cropped_line:\"+cropped_line)\n",
    "                \n",
    "                if prediction == '!': # end of case was just predicted, therefore, stop predicting further into the future\n",
    "                    print('! predicted, end case')\n",
    "                    break\n",
    "                predicted += prediction\n",
    "                #print(\"predicted:\" +predicted)\n",
    "            output = []\n",
    "            \n",
    "            if len(ground_truth)>0:\n",
    "                output.append(caseid)\n",
    "                output.append(prefix_size)\n",
    "                output.append(str(ground_truth).encode(\"utf-8\"))\n",
    "                output.append(str(predicted).encode(\"utf-8\"))\n",
    "                output.append(1 - distance.nlevenshtein(predicted, ground_truth))\n",
    "                dls = 1 - (damerau_levenshtein_distance(str(predicted), str(ground_truth)) / max(len(predicted),len(ground_truth)))\n",
    "                if dls<0:\n",
    "                    dls=0 # we encountered problems with Damerau-Levenshtein Similarity on some linux machines where the default character encoding of the operating system caused it to be negative, this should never be the case\n",
    "                output.append(dls)\n",
    "                output.append(1 - distance.jaccard(predicted, ground_truth))\n",
    "\n",
    "                output.append('')\n",
    "                output.append('')\n",
    "                output.append('')\n",
    "                spamwriter.writerow(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a5e214",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6511f311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next activity accuracy:  0.7069744104365279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         b''       0.00      0.00      0.00         0\n",
      " b'\\xc2\\xa2'       0.00      0.00      0.00        17\n",
      " b'\\xc2\\xa3'       0.00      0.00      0.00        13\n",
      " b'\\xc2\\xa5'       0.00      0.00      0.00         7\n",
      " b'\\xc2\\xa6'       0.00      0.00      0.00         1\n",
      " b'\\xc2\\xa7'       0.75      0.90      0.82      1283\n",
      " b'\\xc2\\xa8'       0.00      0.00      0.00         2\n",
      " b'\\xc2\\xa9'       0.75      0.68      0.72       373\n",
      " b'\\xc2\\xaa'       0.25      0.01      0.02       297\n",
      "\n",
      "    accuracy                           0.71      1993\n",
      "   macro avg       0.19      0.18      0.17      1993\n",
      "weighted avg       0.66      0.71      0.66      1993\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\I541451\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\I541451\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\I541451\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\I541451\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\I541451\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\I541451\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "ground_truth = []\n",
    "predicted = []\n",
    "with open(f'output_files/results/{eventlog_name}_LSTM_next_activity_%s' % eventlog) as file:\n",
    "    reader = csv.reader(file, delimiter=\",\")\n",
    "    # Skip the header\n",
    "    next(reader, None)\n",
    "    for row in reader:\n",
    "        # we do not evaluate the end activity of the case\n",
    "        if len(row) >= 4 and row[2] and row[3]:\n",
    "            ground_truth.append(row[2])\n",
    "            predicted.append(row[3])\n",
    "\n",
    "accuracy = accuracy_score(ground_truth, predicted)\n",
    "print(\"Next activity accuracy: \", accuracy)\n",
    "print(classification_report(ground_truth, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09e3256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
